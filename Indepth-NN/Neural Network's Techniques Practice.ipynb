{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, Y_train_full), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full/255.0\n",
    "x_test = x_test / 255.0\n",
    "x_valid, x_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = Y_train_full[:5000], Y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to scale the inputs to a mean of 0, with a standard deviation of 1\n",
    "pixel_means = x_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = x_train.std(axis=0, keepdims=True)\n",
    "\n",
    "x_train_scaled = (x_train - pixel_means) / pixel_stds\n",
    "x_valid_scaled = (x_valid - pixel_means) / pixel_stds\n",
    "x_test_scaled = (x_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random():\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    return None\n",
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Graph Saving\n",
    "PROJECT_ROOT_DIR = \"./graphs\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing w/ Vanishing/Exploding Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of different weight initializers\n",
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7faa0c0bfb00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-declared initializer w/ more customization\n",
    "\n",
    "#he_normal w/ uniform distribution, using the fan_average (glort/xaiver init)\n",
    "init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg',\n",
    "                                                distribution='uniform')\n",
    "keras.layers.Dense(10, activation='relu', kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7faa8c5a0438>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple use of initalizer\n",
    "keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELU's (rectified linear unit) suffer from 'dying neuron', other options include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leaky RELU manual creation (also part of keras.activations)\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selection of other activation functions\n",
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RELU alterations\n",
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Rectified Linear Unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 1.2810 - accuracy: 0.6205 - val_loss: 0.8869 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.7952 - accuracy: 0.7369 - val_loss: 0.7132 - val_accuracy: 0.7626\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.6817 - accuracy: 0.7726 - val_loss: 0.6385 - val_accuracy: 0.7896\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.6219 - accuracy: 0.7942 - val_loss: 0.5931 - val_accuracy: 0.8016\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.5829 - accuracy: 0.8074 - val_loss: 0.5607 - val_accuracy: 0.8166\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.5552 - accuracy: 0.8173 - val_loss: 0.5355 - val_accuracy: 0.8240\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.5338 - accuracy: 0.8224 - val_loss: 0.5166 - val_accuracy: 0.8300\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.5172 - accuracy: 0.8261 - val_loss: 0.5043 - val_accuracy: 0.8356\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.5039 - accuracy: 0.8305 - val_loss: 0.4889 - val_accuracy: 0.8386\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.4922 - accuracy: 0.8332 - val_loss: 0.4816 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/sample - loss: 0.5154 - accuracy: 0.8259\n"
     ]
    }
   ],
   "source": [
    "#LeakyRELU\n",
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameteric Rectified Linear Unit (PRelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "             optimizer= keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 1.3452 - accuracy: 0.6203 - val_loss: 0.9241 - val_accuracy: 0.7170\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.8196 - accuracy: 0.7364 - val_loss: 0.7313 - val_accuracy: 0.7598\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.6969 - accuracy: 0.7700 - val_loss: 0.6516 - val_accuracy: 0.7882\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.6333 - accuracy: 0.7915 - val_loss: 0.6032 - val_accuracy: 0.8054\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.5916 - accuracy: 0.8049 - val_loss: 0.5689 - val_accuracy: 0.8160\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.5619 - accuracy: 0.8144 - val_loss: 0.5416 - val_accuracy: 0.8228\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.5392 - accuracy: 0.8205 - val_loss: 0.5213 - val_accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 0.5214 - accuracy: 0.8257 - val_loss: 0.5075 - val_accuracy: 0.8350\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.5071 - accuracy: 0.8287 - val_loss: 0.4917 - val_accuracy: 0.8384\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.4946 - accuracy: 0.8321 - val_loss: 0.4839 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9b8207fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.5153 - accuracy: 0.8245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5152998466014862, 0.8245]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PRelu\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Linear Units (ELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation demo ($\\alpha=1$)\", fontsize=15)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7fa9b8147748>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#utilizing ELU \n",
    "keras.layers.Dense(10, activation='elu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='elu'),\n",
    "    keras.layers.Dense(100, activation='elu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "             optimizer= keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s 94us/sample - loss: 1.1400 - accuracy: 0.6525 - val_loss: 0.8021 - val_accuracy: 0.7462\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.7380 - accuracy: 0.7579 - val_loss: 0.6668 - val_accuracy: 0.7804\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.6461 - accuracy: 0.7858 - val_loss: 0.6059 - val_accuracy: 0.8012\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.5966 - accuracy: 0.8008 - val_loss: 0.5682 - val_accuracy: 0.8132\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.5641 - accuracy: 0.8100 - val_loss: 0.5411 - val_accuracy: 0.8198\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.5410 - accuracy: 0.8152 - val_loss: 0.5213 - val_accuracy: 0.8226\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.5234 - accuracy: 0.8206 - val_loss: 0.5058 - val_accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.5096 - accuracy: 0.8242 - val_loss: 0.4949 - val_accuracy: 0.8324\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.4984 - accuracy: 0.8282 - val_loss: 0.4824 - val_accuracy: 0.8358\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.4887 - accuracy: 0.8301 - val_loss: 0.4765 - val_accuracy: 0.8364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 46us/sample - loss: 0.5097 - accuracy: 0.8202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5097105376243591, 0.8202]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elu\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled exponential  linear unit (SELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "during training with a leCun initalization with scaled exponential linear units will self-normalize, solving the problem of vanishing and exploding gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downsides: can't use regularization, dropout, max-normalization, skip connections (aka RNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7fa9b8fbbf28>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementing SELU\n",
    "keras.layers.Dense(10, activation='selu', kernel_initializer='lecun_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'))\n",
    "#hundo layers of hundo neons\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "             optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 26s 466us/sample - loss: 1.0828 - accuracy: 0.5751 - val_loss: 0.8131 - val_accuracy: 0.6756\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 23s 423us/sample - loss: 0.7160 - accuracy: 0.7326 - val_loss: 0.5939 - val_accuracy: 0.7852\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 23s 423us/sample - loss: 0.5887 - accuracy: 0.7851 - val_loss: 0.5875 - val_accuracy: 0.7904\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 23s 426us/sample - loss: 0.5369 - accuracy: 0.8052 - val_loss: 0.5551 - val_accuracy: 0.8090\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 23s 413us/sample - loss: 0.5135 - accuracy: 0.8179 - val_loss: 0.6958 - val_accuracy: 0.7352\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=5, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 189us/sample - loss: 0.7246 - accuracy: 0.7274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7245925815582276, 0.7274]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous architecture w/ RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
    "\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 23s 413us/sample - loss: 1.7822 - accuracy: 0.2732 - val_loss: 1.1945 - val_accuracy: 0.4636\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 21s 389us/sample - loss: 1.1452 - accuracy: 0.5130 - val_loss: 0.9559 - val_accuracy: 0.6098\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 20s 373us/sample - loss: 0.9717 - accuracy: 0.6033 - val_loss: 1.0026 - val_accuracy: 0.5730\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 21s 380us/sample - loss: 0.8138 - accuracy: 0.6735 - val_loss: 0.6852 - val_accuracy: 0.7364\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 21s 374us/sample - loss: 0.8367 - accuracy: 0.6733 - val_loss: 0.7549 - val_accuracy: 0.7224\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=5, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 143us/sample - loss: 0.7812 - accuracy: 0.7147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7812127910614014, 0.7147]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normalization_1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in batch_normalization_1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normalization_1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "             optimizer= keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 8s 154us/sample - loss: 0.8761 - accuracy: 0.7122 - val_loss: 0.5510 - val_accuracy: 0.8232\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.5737 - accuracy: 0.8037 - val_loss: 0.4723 - val_accuracy: 0.8454\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.5142 - accuracy: 0.8230 - val_loss: 0.4376 - val_accuracy: 0.8576\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.4826 - accuracy: 0.8329 - val_loss: 0.4134 - val_accuracy: 0.8638\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.4570 - accuracy: 0.8415 - val_loss: 0.3989 - val_accuracy: 0.8648\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.4432 - accuracy: 0.8457 - val_loss: 0.3869 - val_accuracy: 0.8708\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.4254 - accuracy: 0.8513 - val_loss: 0.3783 - val_accuracy: 0.8704\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.4149 - accuracy: 0.8535 - val_loss: 0.3708 - val_accuracy: 0.8756\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.4015 - accuracy: 0.8597 - val_loss: 0.3636 - val_accuracy: 0.8752\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.3914 - accuracy: 0.8629 - val_loss: 0.3601 - val_accuracy: 0.8756\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes BN works better before the activation function, sert use_bias = False\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 1.0334 - accuracy: 0.6755 - val_loss: 0.6738 - val_accuracy: 0.7832\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.6761 - accuracy: 0.7820 - val_loss: 0.5562 - val_accuracy: 0.8194\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.5929 - accuracy: 0.8056 - val_loss: 0.5006 - val_accuracy: 0.8368\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.5467 - accuracy: 0.8159 - val_loss: 0.4652 - val_accuracy: 0.8452\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.5114 - accuracy: 0.8269 - val_loss: 0.4427 - val_accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 9s 170us/sample - loss: 0.4903 - accuracy: 0.8334 - val_loss: 0.4264 - val_accuracy: 0.8542\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 8s 147us/sample - loss: 0.4723 - accuracy: 0.8375 - val_loss: 0.4127 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 8s 151us/sample - loss: 0.4573 - accuracy: 0.8427 - val_loss: 0.4032 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 8s 144us/sample - loss: 0.4432 - accuracy: 0.8470 - val_loss: 0.3944 - val_accuracy: 0.8638\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 8s 145us/sample - loss: 0.4332 - accuracy: 0.8515 - val_loss: 0.3875 - val_accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple use of gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimzier = keras.optimizers.SGD(clipvalue=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training set into two groups \n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "\n",
    "(x_train_A, y_train_A), (x_train_B, y_train_B) = split_dataset(x_train, y_train)\n",
    "(x_valid_A, y_valid_A), (x_valid_B, y_valid_B) = split_dataset(x_valid, y_valid)\n",
    "(x_test_A, y_test_A), (x_test_B, y_test_B) = split_dataset(x_test, y_test)\n",
    "x_train_B = x_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# creates a 300 layer neuron layer, 100 n, etc.\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
    "model_A.add(keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 276,158\n",
      "Trainable params: 276,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_A.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43986 samples, validate on 4014 samples\n",
      "Epoch 1/20\n",
      "43986/43986 [==============================] - 4s 98us/sample - loss: 0.5902 - accuracy: 0.8130 - val_loss: 0.3782 - val_accuracy: 0.8690\n",
      "Epoch 2/20\n",
      "43986/43986 [==============================] - 4s 95us/sample - loss: 0.3517 - accuracy: 0.8785 - val_loss: 0.3371 - val_accuracy: 0.8837\n",
      "Epoch 3/20\n",
      "43986/43986 [==============================] - 4s 100us/sample - loss: 0.3162 - accuracy: 0.8896 - val_loss: 0.3016 - val_accuracy: 0.8959\n",
      "Epoch 4/20\n",
      "43986/43986 [==============================] - 5s 125us/sample - loss: 0.2969 - accuracy: 0.8973 - val_loss: 0.2912 - val_accuracy: 0.9028\n",
      "Epoch 5/20\n",
      "43986/43986 [==============================] - 5s 117us/sample - loss: 0.2831 - accuracy: 0.9026 - val_loss: 0.2816 - val_accuracy: 0.9016\n",
      "Epoch 6/20\n",
      "43986/43986 [==============================] - 7s 159us/sample - loss: 0.2725 - accuracy: 0.9066 - val_loss: 0.2736 - val_accuracy: 0.9073\n",
      "Epoch 7/20\n",
      "43986/43986 [==============================] - 6s 132us/sample - loss: 0.2644 - accuracy: 0.9094 - val_loss: 0.2651 - val_accuracy: 0.9091\n",
      "Epoch 8/20\n",
      "43986/43986 [==============================] - 7s 160us/sample - loss: 0.2577 - accuracy: 0.9117 - val_loss: 0.2580 - val_accuracy: 0.9126\n",
      "Epoch 9/20\n",
      "43986/43986 [==============================] - 7s 164us/sample - loss: 0.2516 - accuracy: 0.9137 - val_loss: 0.2580 - val_accuracy: 0.9138\n",
      "Epoch 10/20\n",
      "43986/43986 [==============================] - 5s 123us/sample - loss: 0.2465 - accuracy: 0.9152 - val_loss: 0.2521 - val_accuracy: 0.9153\n",
      "Epoch 11/20\n",
      "43986/43986 [==============================] - 6s 129us/sample - loss: 0.2419 - accuracy: 0.9179 - val_loss: 0.2490 - val_accuracy: 0.9165\n",
      "Epoch 12/20\n",
      "43986/43986 [==============================] - 6s 147us/sample - loss: 0.2381 - accuracy: 0.9190 - val_loss: 0.2456 - val_accuracy: 0.9170\n",
      "Epoch 13/20\n",
      "43986/43986 [==============================] - 5s 103us/sample - loss: 0.2347 - accuracy: 0.9196 - val_loss: 0.2448 - val_accuracy: 0.9203\n",
      "Epoch 14/20\n",
      "43986/43986 [==============================] - 4s 100us/sample - loss: 0.2311 - accuracy: 0.9205 - val_loss: 0.2432 - val_accuracy: 0.9175\n",
      "Epoch 15/20\n",
      "43986/43986 [==============================] - 4s 101us/sample - loss: 0.2282 - accuracy: 0.9220 - val_loss: 0.2432 - val_accuracy: 0.9180\n",
      "Epoch 16/20\n",
      "43986/43986 [==============================] - 4s 99us/sample - loss: 0.2255 - accuracy: 0.9227 - val_loss: 0.2410 - val_accuracy: 0.9155\n",
      "Epoch 17/20\n",
      "43986/43986 [==============================] - 4s 100us/sample - loss: 0.2228 - accuracy: 0.9226 - val_loss: 0.2370 - val_accuracy: 0.9178\n",
      "Epoch 18/20\n",
      "43986/43986 [==============================] - 4s 99us/sample - loss: 0.2201 - accuracy: 0.9245 - val_loss: 0.2431 - val_accuracy: 0.9175\n",
      "Epoch 19/20\n",
      "43986/43986 [==============================] - 4s 96us/sample - loss: 0.2176 - accuracy: 0.9252 - val_loss: 0.2607 - val_accuracy: 0.9053\n",
      "Epoch 20/20\n",
      "43986/43986 [==============================] - 4s 101us/sample - loss: 0.2158 - accuracy: 0.9265 - val_loss: 0.2328 - val_accuracy: 0.9208\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(x_train_A, y_train_A, epochs=20, validation_data=(x_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save('model_a.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slightly different model, utilizing the sigmoid function as an exit\n",
    "model_b = keras.models.Sequential()\n",
    "model_b.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_b.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
    "model_b.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.9509 - accuracy: 0.4800 - val_loss: 0.6533 - val_accuracy: 0.5568\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 304us/sample - loss: 0.5837 - accuracy: 0.7100 - val_loss: 0.4825 - val_accuracy: 0.8479\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 340us/sample - loss: 0.4527 - accuracy: 0.8750 - val_loss: 0.4097 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 497us/sample - loss: 0.3869 - accuracy: 0.9050 - val_loss: 0.3630 - val_accuracy: 0.9209\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 369us/sample - loss: 0.3404 - accuracy: 0.9300 - val_loss: 0.3302 - val_accuracy: 0.9280\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 0s 466us/sample - loss: 0.3073 - accuracy: 0.9350 - val_loss: 0.3026 - val_accuracy: 0.9381\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 495us/sample - loss: 0.2797 - accuracy: 0.9400 - val_loss: 0.2790 - val_accuracy: 0.9452\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 311us/sample - loss: 0.2554 - accuracy: 0.9450 - val_loss: 0.2595 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 492us/sample - loss: 0.2355 - accuracy: 0.9600 - val_loss: 0.2439 - val_accuracy: 0.9493\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 532us/sample - loss: 0.2187 - accuracy: 0.9650 - val_loss: 0.2293 - val_accuracy: 0.9523\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 544us/sample - loss: 0.2041 - accuracy: 0.9650 - val_loss: 0.2162 - val_accuracy: 0.9544\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 447us/sample - loss: 0.1906 - accuracy: 0.9650 - val_loss: 0.2049 - val_accuracy: 0.9574\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 514us/sample - loss: 0.1791 - accuracy: 0.9700 - val_loss: 0.1946 - val_accuracy: 0.9594\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 455us/sample - loss: 0.1686 - accuracy: 0.9750 - val_loss: 0.1856 - val_accuracy: 0.9615\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 377us/sample - loss: 0.1591 - accuracy: 0.9750 - val_loss: 0.1765 - val_accuracy: 0.9655\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 465us/sample - loss: 0.1502 - accuracy: 0.9900 - val_loss: 0.1695 - val_accuracy: 0.9655\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 473us/sample - loss: 0.1424 - accuracy: 0.9900 - val_loss: 0.1624 - val_accuracy: 0.9686\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 485us/sample - loss: 0.1351 - accuracy: 0.9900 - val_loss: 0.1567 - val_accuracy: 0.9686\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 352us/sample - loss: 0.1290 - accuracy: 0.9900 - val_loss: 0.1513 - val_accuracy: 0.9696\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 370us/sample - loss: 0.1229 - accuracy: 0.9900 - val_loss: 0.1450 - val_accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "history = model_b.fit(x_train_B, y_train_B, epochs=20, validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model a and b combo,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the models\n",
    "model_A = keras.models.load_model('model_a.h5')\n",
    "#grab all except for the exit layer\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "#apply last layer with sigmoid\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " prevent all the layers from model_a from being trained, bc during intial training since the errors will be quite large, otherwise the weights will be changed in the earlier layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevent training during first iterations\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.5650 - accuracy: 0.6650 - val_loss: 0.5694 - val_accuracy: 0.6531\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 276us/sample - loss: 0.5278 - accuracy: 0.7050 - val_loss: 0.5361 - val_accuracy: 0.6947\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 415us/sample - loss: 0.4950 - accuracy: 0.7400 - val_loss: 0.5060 - val_accuracy: 0.7160\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 352us/sample - loss: 0.4655 - accuracy: 0.7600 - val_loss: 0.4794 - val_accuracy: 0.7383\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(x_train_B, y_train_B, epochs=4, validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/16\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.3883 - accuracy: 0.8200 - val_loss: 0.3367 - val_accuracy: 0.8671\n",
      "Epoch 2/16\n",
      "200/200 [==============================] - 0s 319us/sample - loss: 0.2711 - accuracy: 0.9350 - val_loss: 0.2614 - val_accuracy: 0.9239\n",
      "Epoch 3/16\n",
      "200/200 [==============================] - 0s 366us/sample - loss: 0.2088 - accuracy: 0.9650 - val_loss: 0.2153 - val_accuracy: 0.9503\n",
      "Epoch 4/16\n",
      "200/200 [==============================] - 0s 405us/sample - loss: 0.1699 - accuracy: 0.9800 - val_loss: 0.1842 - val_accuracy: 0.9625\n",
      "Epoch 5/16\n",
      "200/200 [==============================] - 0s 352us/sample - loss: 0.1431 - accuracy: 0.9800 - val_loss: 0.1603 - val_accuracy: 0.9706\n",
      "Epoch 6/16\n",
      "200/200 [==============================] - 0s 426us/sample - loss: 0.1223 - accuracy: 0.9850 - val_loss: 0.1425 - val_accuracy: 0.9787\n",
      "Epoch 7/16\n",
      "200/200 [==============================] - 0s 441us/sample - loss: 0.1068 - accuracy: 0.9950 - val_loss: 0.1294 - val_accuracy: 0.9828\n",
      "Epoch 8/16\n",
      "200/200 [==============================] - 0s 420us/sample - loss: 0.0954 - accuracy: 0.9950 - val_loss: 0.1187 - val_accuracy: 0.9848\n",
      "Epoch 9/16\n",
      "200/200 [==============================] - 0s 360us/sample - loss: 0.0859 - accuracy: 0.9950 - val_loss: 0.1100 - val_accuracy: 0.9848\n",
      "Epoch 10/16\n",
      "200/200 [==============================] - 0s 455us/sample - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9878\n",
      "Epoch 11/16\n",
      "200/200 [==============================] - 0s 399us/sample - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9878\n",
      "Epoch 12/16\n",
      "200/200 [==============================] - 0s 336us/sample - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9888\n",
      "Epoch 13/16\n",
      "200/200 [==============================] - 0s 379us/sample - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "200/200 [==============================] - 0s 495us/sample - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "200/200 [==============================] - 0s 447us/sample - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "200/200 [==============================] - 0s 459us/sample - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9b92ed898>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allow the weights to now be adjusted post-intial training of the combined model\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3), \n",
    "                    metrics=['accuracy'])\n",
    "model_B_on_A.fit(x_train_B, y_train_B, epochs=16, validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 46us/sample - loss: 0.0698 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0697787880897522, 0.9925]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.933333333333337"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparison of the two models\n",
    "(100 -97.05) / (100 - 99.25)\n",
    "#almost 4 times better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloning weights from one model to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Optimizers (Faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nestrov_accelerated_gradient_optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad_optimizer = keras.optimizers.Adagrad(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop_optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "#rho = intial decay rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta_1 = momentum decay rate typically 0.9\n",
    "Beta_2 = scaling decay rate typically initalized to 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamax_optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nestrov adam\n",
    "nadam_optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling:\n",
    "   setting the learning rate as a function to the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default\n",
    "power_scheduler = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=power_scheduler, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.4887 - accuracy: 0.8295 - val_loss: 0.8514 - val_accuracy: 0.6974\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.3821 - accuracy: 0.8639 - val_loss: 0.8081 - val_accuracy: 0.7328\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.3486 - accuracy: 0.8756 - val_loss: 0.7690 - val_accuracy: 0.7598\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.3268 - accuracy: 0.8845 - val_loss: 0.7861 - val_accuracy: 0.7440\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.3103 - accuracy: 0.8881 - val_loss: 0.8373 - val_accuracy: 0.7040\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 8s 151us/sample - loss: 0.2977 - accuracy: 0.8931 - val_loss: 0.8091 - val_accuracy: 0.7240\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 8s 145us/sample - loss: 0.2868 - accuracy: 0.8979 - val_loss: 0.8100 - val_accuracy: 0.7192\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.2778 - accuracy: 0.8999 - val_loss: 0.8322 - val_accuracy: 0.6898\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.2695 - accuracy: 0.9042 - val_loss: 0.8227 - val_accuracy: 0.7110\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.2622 - accuracy: 0.9069 - val_loss: 0.7952 - val_accuracy: 0.7250\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.2562 - accuracy: 0.9090 - val_loss: 0.8429 - val_accuracy: 0.6888\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.2505 - accuracy: 0.9114 - val_loss: 0.8343 - val_accuracy: 0.6888\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.2452 - accuracy: 0.9127 - val_loss: 0.8411 - val_accuracy: 0.6948\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.2404 - accuracy: 0.9149 - val_loss: 0.8035 - val_accuracy: 0.7236\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2360 - accuracy: 0.9171 - val_loss: 0.8778 - val_accuracy: 0.6874\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2318 - accuracy: 0.9185 - val_loss: 0.8529 - val_accuracy: 0.6962\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.2285 - accuracy: 0.9197 - val_loss: 0.8507 - val_accuracy: 0.6942\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.2245 - accuracy: 0.9209 - val_loss: 0.8714 - val_accuracy: 0.6830\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2211 - accuracy: 0.9218 - val_loss: 0.8681 - val_accuracy: 0.6786\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.2180 - accuracy: 0.9238 - val_loss: 0.9008 - val_accuracy: 0.6764\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2151 - accuracy: 0.9245 - val_loss: 0.8829 - val_accuracy: 0.6802\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.2120 - accuracy: 0.9267 - val_loss: 0.8741 - val_accuracy: 0.6796\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2094 - accuracy: 0.9265 - val_loss: 0.8963 - val_accuracy: 0.6730\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.2067 - accuracy: 0.9278 - val_loss: 0.9151 - val_accuracy: 0.6684\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 5s 97us/sample - loss: 0.2047 - accuracy: 0.9294 - val_loss: 0.9095 - val_accuracy: 0.6510\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(x_train_scaled, y_train, epochs=n_epochs, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling:\n",
    "    every 10 times the learning rate is reduced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential decay by epoch\n",
    "def exponential_decay(learning_rate, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return learning_rate*0.1**(epoch /s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(learning_rate=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 12s 213us/sample - loss: 0.8525 - accuracy: 0.7566 - val_loss: 0.6998 - val_accuracy: 0.7630\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.6670 - accuracy: 0.7962 - val_loss: 0.7725 - val_accuracy: 0.7234\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.6302 - accuracy: 0.8084 - val_loss: 0.6147 - val_accuracy: 0.8020\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 11s 199us/sample - loss: 0.5487 - accuracy: 0.8307 - val_loss: 0.6762 - val_accuracy: 0.8400\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.4942 - accuracy: 0.8437 - val_loss: 0.4863 - val_accuracy: 0.8606\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 11s 198us/sample - loss: 0.4377 - accuracy: 0.8602 - val_loss: 0.4912 - val_accuracy: 0.8492\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 11s 199us/sample - loss: 0.4124 - accuracy: 0.8674 - val_loss: 0.5068 - val_accuracy: 0.8378\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.3823 - accuracy: 0.8755 - val_loss: 0.4768 - val_accuracy: 0.8626\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.3502 - accuracy: 0.8832 - val_loss: 0.4573 - val_accuracy: 0.8716\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.3259 - accuracy: 0.8902 - val_loss: 0.5990 - val_accuracy: 0.8652\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.3024 - accuracy: 0.8980 - val_loss: 0.4288 - val_accuracy: 0.8786\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.2811 - accuracy: 0.9051 - val_loss: 0.4472 - val_accuracy: 0.8760\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.2609 - accuracy: 0.9104 - val_loss: 0.4295 - val_accuracy: 0.8840\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.2430 - accuracy: 0.9155 - val_loss: 0.4278 - val_accuracy: 0.8892\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 15s 274us/sample - loss: 0.2262 - accuracy: 0.9211 - val_loss: 0.4552 - val_accuracy: 0.8848\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 20s 367us/sample - loss: 0.2127 - accuracy: 0.9275 - val_loss: 0.4878 - val_accuracy: 0.8792\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 18s 335us/sample - loss: 0.1989 - accuracy: 0.9334 - val_loss: 0.4691 - val_accuracy: 0.8860\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 17s 315us/sample - loss: 0.1807 - accuracy: 0.9379 - val_loss: 0.5106 - val_accuracy: 0.8858\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 18s 321us/sample - loss: 0.1698 - accuracy: 0.9423 - val_loss: 0.5280 - val_accuracy: 0.8824\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 15s 268us/sample - loss: 0.1580 - accuracy: 0.9468 - val_loss: 0.5419 - val_accuracy: 0.8878\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 12s 211us/sample - loss: 0.1479 - accuracy: 0.9510 - val_loss: 0.5643 - val_accuracy: 0.8874\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 12s 212us/sample - loss: 0.1356 - accuracy: 0.9555 - val_loss: 0.6002 - val_accuracy: 0.8898\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 11s 209us/sample - loss: 0.1279 - accuracy: 0.9584 - val_loss: 0.6033 - val_accuracy: 0.8894\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 12s 210us/sample - loss: 0.1203 - accuracy: 0.9609 - val_loss: 0.6240 - val_accuracy: 0.8852\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 12s 210us/sample - loss: 0.1116 - accuracy: 0.9645 - val_loss: 0.6228 - val_accuracy: 0.8888\n"
     ]
    }
   ],
   "source": [
    "learning_rate_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train, epochs=n_epochs, validation_data=(x_valid_scaled, y_valid),\n",
    "                   callbacks=[learning_rate_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization of the change of the learning curves\n",
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs -1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating the learning rate on each iteration compared to each epoch\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "    #function names need to be exact to run\n",
    "    def on_batch_begin(self, batch, logs= None):\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1/s))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs= logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 34s 609us/sample - loss: 0.7972 - accuracy: 0.7657 - val_loss: 0.7054 - val_accuracy: 0.7094\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 32s 576us/sample - loss: 0.6656 - accuracy: 0.7985 - val_loss: 0.6093 - val_accuracy: 0.8108\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 30s 551us/sample - loss: 0.5741 - accuracy: 0.8208 - val_loss: 0.5821 - val_accuracy: 0.8092\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 33s 593us/sample - loss: 0.5184 - accuracy: 0.8371 - val_loss: 0.6780 - val_accuracy: 0.8416\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 33s 604us/sample - loss: 0.4665 - accuracy: 0.8508 - val_loss: 0.4713 - val_accuracy: 0.8492\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 31s 569us/sample - loss: 0.4376 - accuracy: 0.8596 - val_loss: 0.5338 - val_accuracy: 0.8500\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 32s 584us/sample - loss: 0.4054 - accuracy: 0.8688 - val_loss: 0.5742 - val_accuracy: 0.8620\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 19s 340us/sample - loss: 0.3846 - accuracy: 0.8772 - val_loss: 0.4735 - val_accuracy: 0.8584\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 13s 233us/sample - loss: 0.3373 - accuracy: 0.8867 - val_loss: 0.4454 - val_accuracy: 0.8758\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 13s 235us/sample - loss: 0.3231 - accuracy: 0.8925 - val_loss: 0.4382 - val_accuracy: 0.8730\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 13s 237us/sample - loss: 0.2945 - accuracy: 0.8996 - val_loss: 0.4400 - val_accuracy: 0.8796\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 13s 234us/sample - loss: 0.2772 - accuracy: 0.9072 - val_loss: 0.4299 - val_accuracy: 0.8794\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 13s 237us/sample - loss: 0.2510 - accuracy: 0.9139 - val_loss: 0.4707 - val_accuracy: 0.8826\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 12s 224us/sample - loss: 0.2394 - accuracy: 0.9179 - val_loss: 0.4933 - val_accuracy: 0.8822\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 13s 232us/sample - loss: 0.2215 - accuracy: 0.9240 - val_loss: 0.5031 - val_accuracy: 0.8794\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 13s 233us/sample - loss: 0.2033 - accuracy: 0.9299 - val_loss: 0.4842 - val_accuracy: 0.8816\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 13s 243us/sample - loss: 0.1872 - accuracy: 0.9360 - val_loss: 0.4680 - val_accuracy: 0.8886\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 16s 284us/sample - loss: 0.1767 - accuracy: 0.9401 - val_loss: 0.5036 - val_accuracy: 0.8892\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 14s 254us/sample - loss: 0.1632 - accuracy: 0.9447 - val_loss: 0.5283 - val_accuracy: 0.8842\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 13s 240us/sample - loss: 0.1524 - accuracy: 0.9487 - val_loss: 0.4802 - val_accuracy: 0.8876\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 14s 247us/sample - loss: 0.1447 - accuracy: 0.9519 - val_loss: 0.5397 - val_accuracy: 0.8874\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 14s 250us/sample - loss: 0.1318 - accuracy: 0.9564 - val_loss: 0.5565 - val_accuracy: 0.8872\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 14s 249us/sample - loss: 0.1252 - accuracy: 0.9591 - val_loss: 0.5674 - val_accuracy: 0.8874\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 14s 253us/sample - loss: 0.1173 - accuracy: 0.9627 - val_loss: 0.6197 - val_accuracy: 0.8874\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 15s 271us/sample - loss: 0.1105 - accuracy: 0.9651 - val_loss: 0.6037 - val_accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "learning_rate = 0.01 \n",
    "optimizer = keras.optimizers.Nadam(lr=learning_rate)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(x_train) // 32 #the number of steps in 20 epochs with a batch size of 32\n",
    "exp_decay = ExponentialDecay(s)\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train, epochs=n_epochs, validation_data=(x_valid_scaled, y_valid),\n",
    "                   callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded\n",
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch< 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft coded\n",
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5,15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 13s 230us/sample - loss: 0.8785 - accuracy: 0.7567 - val_loss: 0.7550 - val_accuracy: 0.7324\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 14s 253us/sample - loss: 0.9106 - accuracy: 0.7376 - val_loss: 0.9761 - val_accuracy: 0.7808\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 14s 262us/sample - loss: 0.9290 - accuracy: 0.7219 - val_loss: 0.7684 - val_accuracy: 0.7960\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 13s 235us/sample - loss: 0.7701 - accuracy: 0.7811 - val_loss: 0.8208 - val_accuracy: 0.8048\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 12s 217us/sample - loss: 0.7432 - accuracy: 0.7874 - val_loss: 0.8192 - val_accuracy: 0.7680\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.5237 - accuracy: 0.8387 - val_loss: 0.6621 - val_accuracy: 0.8458\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 11s 199us/sample - loss: 0.4814 - accuracy: 0.8548 - val_loss: 0.6130 - val_accuracy: 0.8384\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.4608 - accuracy: 0.8604 - val_loss: 0.5784 - val_accuracy: 0.8486\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.4576 - accuracy: 0.8641 - val_loss: 0.5330 - val_accuracy: 0.8550\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 11s 194us/sample - loss: 0.4429 - accuracy: 0.8664 - val_loss: 0.5867 - val_accuracy: 0.8366\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.4389 - accuracy: 0.8710 - val_loss: 0.5633 - val_accuracy: 0.8620\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.4271 - accuracy: 0.8743 - val_loss: 0.5739 - val_accuracy: 0.8470\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.4159 - accuracy: 0.8765 - val_loss: 0.6177 - val_accuracy: 0.8564\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.4128 - accuracy: 0.8789 - val_loss: 0.6273 - val_accuracy: 0.8680\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.3992 - accuracy: 0.8830 - val_loss: 0.6752 - val_accuracy: 0.8562\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.2723 - accuracy: 0.9141 - val_loss: 0.5252 - val_accuracy: 0.8760\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 11s 208us/sample - loss: 0.2501 - accuracy: 0.9201 - val_loss: 0.5366 - val_accuracy: 0.8834\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.2402 - accuracy: 0.9222 - val_loss: 0.5293 - val_accuracy: 0.8802\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.2296 - accuracy: 0.9262 - val_loss: 0.5622 - val_accuracy: 0.8786\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 11s 208us/sample - loss: 0.2240 - accuracy: 0.9288 - val_loss: 0.5662 - val_accuracy: 0.8804\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.2154 - accuracy: 0.9323 - val_loss: 0.5688 - val_accuracy: 0.8818\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 11s 209us/sample - loss: 0.2060 - accuracy: 0.9351 - val_loss: 0.6037 - val_accuracy: 0.8804\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.2035 - accuracy: 0.9358 - val_loss: 0.5846 - val_accuracy: 0.8834\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 11s 205us/sample - loss: 0.1946 - accuracy: 0.9395 - val_loss: 0.6271 - val_accuracy: 0.8826\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 12s 215us/sample - loss: 0.1889 - accuracy: 0.9418 - val_loss: 0.6529 - val_accuracy: 0.8804\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "epoch_num = 25\n",
    "\n",
    "history= model.fit(x_train_scaled, y_train, epochs=epoch_num, validation_data=(x_valid_scaled, y_valid), \n",
    "                  callbacks=[learning_rate_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling:\n",
    "   reducing learning rate when the error rate stops dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factor = amount to reduce by (lr* factor) \n",
    "#patience = number of epochs w/ no improvement\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.5949 - accuracy: 0.8070 - val_loss: 0.4849 - val_accuracy: 0.8474\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.5248 - accuracy: 0.8335 - val_loss: 0.5306 - val_accuracy: 0.8420\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.5129 - accuracy: 0.8417 - val_loss: 0.4877 - val_accuracy: 0.8458\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.5123 - accuracy: 0.8465 - val_loss: 0.7664 - val_accuracy: 0.8408\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.5127 - accuracy: 0.8520 - val_loss: 0.6294 - val_accuracy: 0.8406\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 6s 117us/sample - loss: 0.5032 - accuracy: 0.8539 - val_loss: 0.6202 - val_accuracy: 0.8528\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.2998 - accuracy: 0.8947 - val_loss: 0.3833 - val_accuracy: 0.8828\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2548 - accuracy: 0.9064 - val_loss: 0.3992 - val_accuracy: 0.8790\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.2324 - accuracy: 0.9151 - val_loss: 0.3900 - val_accuracy: 0.8858\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2167 - accuracy: 0.9189 - val_loss: 0.4037 - val_accuracy: 0.8870\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.2089 - accuracy: 0.9226 - val_loss: 0.4219 - val_accuracy: 0.8804\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.2015 - accuracy: 0.9262 - val_loss: 0.4482 - val_accuracy: 0.8846\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.1426 - accuracy: 0.9445 - val_loss: 0.4081 - val_accuracy: 0.8946\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.1248 - accuracy: 0.9522 - val_loss: 0.4272 - val_accuracy: 0.8942\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 0.1189 - accuracy: 0.9541 - val_loss: 0.4355 - val_accuracy: 0.8926\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.1101 - accuracy: 0.9569 - val_loss: 0.4489 - val_accuracy: 0.8906\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.1034 - accuracy: 0.9603 - val_loss: 0.4536 - val_accuracy: 0.8944\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.0815 - accuracy: 0.9693 - val_loss: 0.4557 - val_accuracy: 0.8948\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.0749 - accuracy: 0.9724 - val_loss: 0.4712 - val_accuracy: 0.8938\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.0714 - accuracy: 0.9737 - val_loss: 0.4736 - val_accuracy: 0.8972\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.4948 - val_accuracy: 0.8954\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.0645 - accuracy: 0.9773 - val_loss: 0.4991 - val_accuracy: 0.8968\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.5024 - val_accuracy: 0.8944\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.0525 - accuracy: 0.9823 - val_loss: 0.5108 - val_accuracy: 0.8956\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 5s 100us/sample - loss: 0.0507 - accuracy: 0.9829 - val_loss: 0.5160 - val_accuracy: 0.8964\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "history = model.fit(x_train_scaled, y_train, epochs=epochs, validation_data=(x_valid_scaled, y_valid), \n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization of the performance learning scheduling technique\n",
    "\n",
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy implementation through tf.keras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "piecewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_per_epoch = 10 #example\n",
    "#piecewise function\n",
    "piecewise_learning = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, .001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_learning = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Cycle technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea to increase the learning rate half way through the entire number of epochs, then decrease the learning rate through the second half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the method\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "        \n",
    "def find_learning_rate( model, x, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(x) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    \n",
    "    history = model.fit(x, y, epochs=epochs, batch_size=batch_size, callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_learning_rate_vs_loss(rate, losses):\n",
    "    plt.plot(rate, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) /2])\n",
    "    plt.xlabel(\"Learning Rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples\n",
      "55000/55000 [==============================] - 2s 41us/sample - loss: nan - accuracy: 0.3901\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, x_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_learning_rate_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None, last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate /10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration =  (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "        \n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2- rate1) * (self.iterations - iter1) / (iter2 - iter1) + rate1)\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iterations < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteartion < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration, self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations, self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iterations += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.6576 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.8300\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4587 - accuracy: 0.8387 - val_loss: 0.4316 - val_accuracy: 0.8490\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 6s 107us/sample - loss: 0.4119 - accuracy: 0.8560 - val_loss: 0.4117 - val_accuracy: 0.8580\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.3842 - accuracy: 0.8657 - val_loss: 0.3920 - val_accuracy: 0.8636\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.3636 - accuracy: 0.8708 - val_loss: 0.3739 - val_accuracy: 0.8710\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 6s 107us/sample - loss: 0.3460 - accuracy: 0.8766 - val_loss: 0.3741 - val_accuracy: 0.8692\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.3312 - accuracy: 0.8818 - val_loss: 0.3759 - val_accuracy: 0.8648\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.3194 - accuracy: 0.8844 - val_loss: 0.3586 - val_accuracy: 0.8754\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.3056 - accuracy: 0.8900 - val_loss: 0.3473 - val_accuracy: 0.8816\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.2943 - accuracy: 0.8934 - val_loss: 0.4008 - val_accuracy: 0.8554\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 5s 93us/sample - loss: 0.2845 - accuracy: 0.8958 - val_loss: 0.3443 - val_accuracy: 0.8828\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.2720 - accuracy: 0.9017 - val_loss: 0.3349 - val_accuracy: 0.8802\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 6s 107us/sample - loss: 0.2538 - accuracy: 0.9093 - val_loss: 0.3381 - val_accuracy: 0.8828\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.2421 - accuracy: 0.9124 - val_loss: 0.3328 - val_accuracy: 0.8854\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2290 - accuracy: 0.9174 - val_loss: 0.3236 - val_accuracy: 0.8840\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2169 - accuracy: 0.9220 - val_loss: 0.3337 - val_accuracy: 0.8862\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 0.2068 - accuracy: 0.9265 - val_loss: 0.3211 - val_accuracy: 0.8874\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.1978 - accuracy: 0.9301 - val_loss: 0.3188 - val_accuracy: 0.8886\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.1894 - accuracy: 0.9327 - val_loss: 0.3272 - val_accuracy: 0.8852\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.1820 - accuracy: 0.9374 - val_loss: 0.3196 - val_accuracy: 0.8916\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.1758 - accuracy: 0.9397 - val_loss: 0.3163 - val_accuracy: 0.8932\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.1702 - accuracy: 0.9418 - val_loss: 0.3178 - val_accuracy: 0.8934\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 6s 114us/sample - loss: 0.1658 - accuracy: 0.9441 - val_loss: 0.3168 - val_accuracy: 0.8954\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.1630 - accuracy: 0.9452 - val_loss: 0.3168 - val_accuracy: 0.8932\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.1612 - accuracy: 0.9464 - val_loss: 0.3171 - val_accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "number_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(x_train) // batch_size * number_epochs, max_rate=0.05)\n",
    "history = model.fit(x_train_scaled, y_train, epochs= number_epochs, batch_size=batch_size,\n",
    "                   validation_data=(x_valid_scaled, y_valid), callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.3379 - accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3379229620754719, 0.8851]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Regularization:\n",
    "    to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  l1 and l2 regularization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple usage of just l2 reg on layer\n",
    "layer = keras.layers.Dense(1, activation='relu', kernel_initializer='he_normal', \n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 1.5735 - accuracy: 0.8126 - val_loss: 0.7327 - val_accuracy: 0.8222\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 12s 215us/sample - loss: 0.7186 - accuracy: 0.8260 - val_loss: 0.6929 - val_accuracy: 0.8338\n"
     ]
    }
   ],
   "source": [
    "#simple model using the l2\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    #using the exponential linear unit activation function with it\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "history = model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "#quick layer building\n",
    "RegularizedDense = partial(keras.layers.Dense, \n",
    "                          activation='elu',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 13s 229us/sample - loss: 1.6006 - accuracy: 0.8129 - val_loss: 0.7374 - val_accuracy: 0.8236\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 12s 218us/sample - loss: 0.7179 - accuracy: 0.8265 - val_loss: 0.6905 - val_accuracy: 0.8356\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.5686 - accuracy: 0.8031 - val_loss: 0.3809 - val_accuracy: 0.8608\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 11s 198us/sample - loss: 0.4212 - accuracy: 0.8466 - val_loss: 0.3379 - val_accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2), #20% dropout \n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha dropout:\n",
    "   dropout that keeps the mean and variances of inputs of their original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 8s 154us/sample - loss: 0.6614 - accuracy: 0.7614 - val_loss: 0.6682 - val_accuracy: 0.8262\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.5526 - accuracy: 0.7971 - val_loss: 0.5835 - val_accuracy: 0.8370\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.5261 - accuracy: 0.8066 - val_loss: 0.5318 - val_accuracy: 0.8532\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.5077 - accuracy: 0.8113 - val_loss: 0.4917 - val_accuracy: 0.8614\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.4934 - accuracy: 0.8180 - val_loss: 0.5006 - val_accuracy: 0.8588\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.4835 - accuracy: 0.8194 - val_loss: 0.5177 - val_accuracy: 0.8534\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.4711 - accuracy: 0.8257 - val_loss: 0.4566 - val_accuracy: 0.8658\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.4645 - accuracy: 0.8269 - val_loss: 0.4604 - val_accuracy: 0.8578\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.4572 - accuracy: 0.8313 - val_loss: 0.4572 - val_accuracy: 0.8628\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.4506 - accuracy: 0.8330 - val_loss: 0.4313 - val_accuracy: 0.8658\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.4472 - accuracy: 0.8336 - val_loss: 0.4586 - val_accuracy: 0.8670\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 7s 124us/sample - loss: 0.4472 - accuracy: 0.8337 - val_loss: 0.4452 - val_accuracy: 0.8676\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.4411 - accuracy: 0.8355 - val_loss: 0.4589 - val_accuracy: 0.8690\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.4335 - accuracy: 0.8385 - val_loss: 0.4898 - val_accuracy: 0.8702\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.4327 - accuracy: 0.8394 - val_loss: 0.4226 - val_accuracy: 0.8778\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.4297 - accuracy: 0.8410 - val_loss: 0.4769 - val_accuracy: 0.8630\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.4281 - accuracy: 0.8399 - val_loss: 0.4467 - val_accuracy: 0.8770\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.4234 - accuracy: 0.8427 - val_loss: 0.4418 - val_accuracy: 0.8746\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.4229 - accuracy: 0.8432 - val_loss: 0.4041 - val_accuracy: 0.8740\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.4196 - accuracy: 0.8450 - val_loss: 0.4169 - val_accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "accuracy = ['accuracy']\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "n_epochs = 20\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=accuracy)\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train, epochs=n_epochs, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.5074 - accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5073673460304737, 0.865]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout:\n",
    "     monte carlo, which is just essentially stacking predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0427 10:52:06.219471 139753668679488 base_layer.py:1790] Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make 100 predictions on the model with test set\n",
    "y_probas = np.stack([model(x_test_scaled, training=True) for sample in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the mean of the 100 predictions \n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to view predictions, w/out dropout\n",
    "np.round(model.predict(x_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.7 , 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.01, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.23, 0.03, 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.15, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.06, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.33, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.05, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.26, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.1 , 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.1 , 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.07, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.3 , 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.14, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.1 , 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.18, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.43, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.16, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.74, 0.  , 0.04, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.4 , 0.03, 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.6 , 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.2 , 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.09, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.07, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.01, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.09, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.09, 0.  , 0.63]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.27, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.57, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.1 , 0.  , 0.51]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.08, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.03, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.01, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.6 , 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.23, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.11, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.09, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.06, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.24, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.29, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.1 , 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.19, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.03, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.34, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.05, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.44, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.41, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.55, 0.  , 0.04, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.01, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.16, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.52, 0.  , 0.36]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.13, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.18, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.1 , 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.03, 0.  , 0.55]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction when the dropout is activated \n",
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No implementation yet\n",
    "class MC_Dropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training= True)\n",
    "    \n",
    "class MC_Alpha_Dropout(keras.layers.AlphaDropout):\n",
    "        def call(self, inputs):\n",
    "            return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like training = True, takes the previous model's architecture\n",
    "mc_model = keras.models.Sequential([\n",
    "    MC_Alpha_Dropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc__alpha__dropout (MC_Alpha (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "mc__alpha__dropout_1 (MC_Alp (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "mc__alpha__dropout_2 (MC_Alp (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.9,\n",
       " 'nesterov': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.get_config() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.compile(loss=loss, optimizer=optimizer, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update weights from the previous model\n",
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.17, 0.  , 0.75]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the mc dropout model, aggergated results \n",
    "np.round(np.mean([mc_model.predict(x_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Norm \n",
    "    Takes the absolute value of the weights |w| < r (r hyperparameter for max-norm)\n",
    "    -computed after each training step and rescaled if neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_layer = keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                   kernel_constraint= keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 12s 222us/sample - loss: 0.4729 - accuracy: 0.8336 - val_loss: 0.4022 - val_accuracy: 0.8578\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 11s 204us/sample - loss: 0.3564 - accuracy: 0.8686 - val_loss: 0.3439 - val_accuracy: 0.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1a3c391a20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "#partial function again, \n",
    "MaxNormDense = partial(keras.layers.Dense, activation='selu', kernel_initializer='lecun_normal', \n",
    "                      kernel_constraint= keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=loss, optimizer='nadam', metrics=accuracy)\n",
    "n_epochs = 2\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs= n_epochs, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rule of thumb for defaults:\n",
    "kernel_init = HE normal\n",
    "activation_fn = ELU\n",
    "normalization = none\n",
    "regularization = early stopping\n",
    "optimizer = momentum \n",
    "learning rate schedule = 1 cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
