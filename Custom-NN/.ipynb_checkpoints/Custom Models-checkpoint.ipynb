{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def set_random():\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    return None\n",
    "set_random()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common, 2x3 matrix \n",
    "t = tf.constant([[1.,2., 3.], [4., 5., 6.]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [4.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the first of each array\n",
    "t[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all but the first of each array\n",
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get only the first array\n",
    "t[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all but the first array\n",
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gt 2nd location in each array only\n",
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras \n",
    "k = keras.backend\n",
    "#adds 10 to each location in within the array\n",
    "k.square(k.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Numpy and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2., 4., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to tensorflow constant\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting tf constant to numpy array\n",
    "np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squaring with tf and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with conflicting types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: add/\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: add/\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "#use the cast method \n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)\n",
    "\n",
    "#can also be done w/ numpy through assign method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b'hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assigned values for the letters \n",
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit='UTF8_CHAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the length of all the indexes\n",
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decode all characters in each location of the array\n",
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged Tensors\n",
    "    (nested variable-length lists), good for non-uniform shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "# copies array to the end of array\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "#appends into the 2nd dimension of the arrays\n",
    "r3 = tf.ragged.constant([[68, 69, 70],[71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change to tensor\n",
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#indices mainly containing 0's\n",
    "s = tf.SparseTensor(indices =[[0, 1], [1,0], [2,3]],\n",
    "                   values=[1., 2., 3.],\n",
    "                   dense_shape=[3, 4])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conversion to dense\n",
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([2. 4. 6.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#multiplication of values\n",
    "s2 = s * 2.0\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'int'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "# multiples sparse tensor by dense matrix\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0,1]],\n",
    "                    values=[1., 2.],\n",
    "                    dense_shape=[3,4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to convert to dense array\n",
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine sets w/ only values in unique locations\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine only unique values from each set\n",
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine only alike values in both sets\n",
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplication\n",
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in the 0 index array, location 1 assign new value 42\n",
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the last location of both arrays set to 0 and 1\n",
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0,0], [1,2]],\n",
    "                   updates=[100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices( values= [[1., 2., 3.], [4., 5., 6.]],\n",
    "                            indices=[1,0])\n",
    "# reverse first dimension\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need decimal point for the float, otherwise tries to \n",
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 4.]))\n",
    "array = array.write(2, tf.constant([5., 6.]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nulls the values of the location and reads them out\n",
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2.       , 2.6666667], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 6.222223 ], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Functions\n",
    "    california housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, Y_train_full, Y_test = train_test_split(housing.data, \n",
    "                                                             housing.target.reshape(-1, 1),\n",
    "                                                             random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, Y_train_full, \n",
    "                                                     random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(X_train)\n",
    "x_valid_scaled = scaler.fit_transform(X_valid)\n",
    "x_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT IT \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the model in a simple one layer\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal', \n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 0.6247 - mae: 0.9969 - val_loss: 0.2505 - val_mae: 0.5660\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.2193 - mae: 0.5176 - val_loss: 0.2148 - val_mae: 0.5166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21e014a780>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model with a custom object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nothing special when saving, however...\n",
    "model.save(\"model_with_cst_huber_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when loading the model back, need to assign it to a variable\n",
    "model = keras.models.load_model(\"model_with_cst_huber_loss.h5\", \n",
    "                         custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 2s 147us/sample - loss: 0.2056 - mae: 0.4982 - val_loss: 0.2113 - val_mae: 0.5158\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 171us/sample - loss: 0.2006 - mae: 0.4911 - val_loss: 0.2072 - val_mae: 0.5049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21de70de48>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifiying the custom function to take open parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions allows the error size to be changed\n",
    "def create_huber_fn(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the model with huber_fn w/ threshold =2 \n",
    "model.compile(loss=create_huber_fn(2.0), optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 3s 297us/sample - loss: 0.2229 - mae: 0.4893 - val_loss: 0.2341 - val_mae: 0.5184\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 0.2189 - mae: 0.4856 - val_loss: 0.2288 - val_mae: 0.5013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21de645780>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "         validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the custom model with custom params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again save as normal\n",
    "model.save('model_with_custom_loss_threshold.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading define the params, specify the threshold\n",
    "model = keras.models.load_model('model_with_custom_loss_threshold.h5', \n",
    "                                custom_objects={'huber_fn': create_huber_fn(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to save the current threshold, without having to declare it when loading the model, make a subclass of the keras.losses.loss class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sublcass of keras.losses.loss class\n",
    "class Huberloss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 /2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    #maintains the current config\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal',\n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 4s 303us/sample - loss: 0.6934 - mae: 0.8818 - val_loss: 0.2609 - val_mae: 0.5345\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 196us/sample - loss: 0.2402 - mae: 0.5077 - val_loss: 0.2378 - val_mae: 0.5172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21dd354898>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=Huberloss(2.0), optimizer='nadam', metrics=['mae'])\n",
    "model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model as norm\n",
    "model.save('model_with_custom_loss_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem 25956\n",
    "# model = keras.models.load_model('model_with_custom_loss_class.h5',\n",
    "#                                convert_custom_objects={'Huberloss': Huberloss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replicas\n",
    "#example of custom activation function\n",
    "def softplus_replicate(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def glort_init_replicate(shape, dtype=tf.float32):\n",
    "    std_dev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev= std_dev, dtype=dtype)\n",
    "\n",
    "\n",
    "def l1_regularizer_replicate(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def positive_weights_replicate(weights):\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_layer = keras.layers.Dense(1, activation=softplus_replicate, \n",
    "                          kernel_initializer=glort_init_replicate,\n",
    "                          kernel_regularizer=l1_regularizer_replicate,\n",
    "                          kernel_constraint=positive_weights_replicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal',\n",
    "                    input_shape=input_shape),\n",
    "    custom_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 5s 395us/sample - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 191us/sample - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21dd14be10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_saved_with_custom_parts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model with custom parts\n",
    "model = keras.models.load_model('model_saved_with_custom_parts.h5',\n",
    "                               custom_objects={\n",
    "                                   #naming needs to be consistent\n",
    "                                   'l1_regularizer_replicate': l1_regularizer_replicate,\n",
    "                                   'glort_init_replicate': glort_init_replicate,\n",
    "                                   'softplus_replicate': softplus_replicate,\n",
    "                                   'positive_weights_replicate': positive_weights_replicate\n",
    "                               })\n",
    "\n",
    "#in demo lambda is called on positive weights, but gives an error when ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 Regularizer using the subclass build from keras\n",
    "\n",
    "class Custom_l1_regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {'factor': self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "standard_input_layer = keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal',\n",
    "                                         input_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standard_input_layer,\n",
    "    keras.layers.Dense(1, \n",
    "                      activation=softplus_replicate,\n",
    "                      kernel_regularizer=Custom_l1_regularizer(0.01), \n",
    "                      kernel_constraint=positive_weights_replicate,\n",
    "                      kernel_initializer=glort_init_replicate)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 4s 359us/sample - loss: 1.6339 - mae: 0.8887 - val_loss: 0.8485 - val_mae: 0.6216\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 206us/sample - loss: 0.6739 - mae: 0.5454 - val_loss: 0.6463 - val_mae: 0.5506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21de6448d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save('custom_model_w_multi_custom_facets.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model\n",
    "model = keras.models.load_model('custom_model_w_multi_custom_facets.h5',\n",
    "                               custom_objects={\n",
    "                                   'Custom_l1_regularizer':Custom_l1_regularizer,\n",
    "                                   'glort_init_replicate': glort_init_replicate,\n",
    "                                   'softplus_replicate': softplus_replicate,\n",
    "                                   'positive_weights_replicate': positive_weights_replicate\n",
    "                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = keras.models.Sequential([\n",
    "    standard_input_layer,\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_model.compile(loss='mse', optimizer='nadam', metrics=[create_huber_fn(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 3s 293us/sample - loss: 1.5649 - huber_fn: 0.6999 - val_loss: 0.5690 - val_huber_fn: 0.2735\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 167us/sample - loss: 0.5079 - huber_fn: 0.2448 - val_loss: 0.5112 - val_huber_fn: 0.2486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21c477ad68>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(x_train_scaled, y_train, epochs=2, \n",
    "                validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning:\n",
    "       using the same fucntion for both loss and metrics will give different results, caused by floating point precision error. As well as other errors:\n",
    "       - batch weighted mean is just mean of what the model has seen so far\n",
    "       - ^ same for the weights, is just the mean of what has been seen so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber_fn(2.0), optimizer='nadam', metrics=[create_huber_fn(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.random.rand(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0501 13:35:01.055746 139787207567168 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 3s 278us/sample - loss: 0.1644 - huber_fn: 0.2391\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.1523 - huber_fn: 0.2277\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16444885539377074, 0.11864791044804247)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of the warning\n",
    "history.history['loss'][0], history.history['huber_fn'][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = keras.metrics.Precision()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Streaming Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Huber_Metric(keras.metrics.Metric):\n",
    "    \n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) \n",
    "        self.threshold = threshold\n",
    "        self.total = self.add_weight('total', initializer=\"zeros\")\n",
    "        self.count = self.add_weight('count', initializer=\"zeros\")\n",
    "        \n",
    "    def huber_fn(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_error = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 /2\n",
    "        return tf.where(is_small_error, squared_error, linear_loss)\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight = None):\n",
    "        metric= self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def get_confg(self):\n",
    "        base_config = super().get_confg()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "m = Huber_Metric(2.0)\n",
    "\n",
    "#total = 2 * |10 -2 | - 2^2/2 = 14\n",
    "#count = 1\n",
    "#result: 14/ 1 = 14\n",
    "m(tf.constant([[2.0]]), tf.constant([[10.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implmenting through a subclass \n",
    "simple_model.compile(loss=create_huber_fn(2.0), optimizer='nadam', metrics=[Huber_Metric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 3s 241us/sample - loss: 0.2318 - huber__metric_1: 0.2318\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 142us/sample - loss: 0.2243 - huber__metric_1: 0.2243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21c478ef98>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(x_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.save('model_with_custom_metrics.h5')\n",
    "#unable to get the model to load although again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.metrics[0].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better implementation of the huber metric that allows for more variety in shapes and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name=\"HuberMetric\", dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber_fn(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "        \n",
    "    def get_confg(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold':self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='selu', kernel_initializer=\"lecun_normal\", \n",
    "                      input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=keras.losses.Huber(2.0), optimizer='nadam',\n",
    "             weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "#getting an error of NoneType object not callable, reproduced on sample code\n",
    "#history = model.fit(x_train_scaled, y_train, epochs=2, sample_weight=sample_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 3s 287us/sample - loss: 1.2222 - val_loss: 0.5991\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 2s 160us/sample - loss: 0.4667 - val_loss: 0.4775\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 2s 164us/sample - loss: 0.4109 - val_loss: 0.4524\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 2s 168us/sample - loss: 0.3903 - val_loss: 0.4396\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 2s 157us/sample - loss: 0.3753 - val_loss: 0.4548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21c42e4e48>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=5, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 1s 100us/sample - loss: 0.4164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41639613070229226"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom class layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units], initializer='zeros')\n",
    "        super().build(batch_input_shape)   #req. at end\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return { **base_config, 'units': self.units, \n",
    "               'activation': keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    Custom_Dense(30, activation='relu', input_shape=input_shape),\n",
    "    Custom_Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 3s 250us/sample - loss: 2.6164 - val_loss: 0.8713\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 166us/sample - loss: 0.7014 - val_loss: 0.6294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21c67a8160>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 89us/sample - loss: 0.5456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5456490943598192"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('custom_layer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('custom_layer_model.h5', custom_objects={\n",
    "    \"Custom_Dense\": Custom_Dense\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom multi-layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Layer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = keras.layers.Input(shape=[2])\n",
    "input_2 = keras.layers.Input(shape=[2])\n",
    "outputs1, output2 = Multi_Layer()((input_1, input_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Gaussian Noise to custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_Guassian_Noise(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "        \n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 3s 241us/sample - loss: 0.4852 - val_loss: 0.4902\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 165us/sample - loss: 0.4161 - val_loss: 0.4504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21df883240>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2, \n",
    "        validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 84us/sample - loss: 0.4118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4117879684812339"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_scaled = x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        self.n_layers = n_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation='elu', \n",
    "                                          kernel_initializer='he_normal')\n",
    "                      for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z = inputs\n",
    "        for layer in self.hidden:\n",
    "            z = layer(z)\n",
    "        return inputs + z\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,  \n",
    "               'n_layers': self.n_layers, \n",
    "               'n_neurons': self.n_neurons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Regressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden1 = keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal')\n",
    "        \n",
    "        self.block1 = Residual_Block(2, 30)\n",
    "        self.block2 = Residual_Block(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z = self.hidden1(inputs)\n",
    "        for _ in range(1 +3):\n",
    "            z = self.block1(z)\n",
    "            return self.out(z)\n",
    "        \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \n",
    "               \"output_dim\": self.output_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Residual_Regressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 3s 287us/sample - loss: 1.1566\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 2s 177us/sample - loss: 0.4667\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 2s 169us/sample - loss: 0.4104\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 2s 153us/sample - loss: 0.3928\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 2s 163us/sample - loss: 0.3790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 1s 126us/sample - loss: 0.4473\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test_scaled, Y_test)\n",
    "y_pred = model.predict(x_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0501 13:35:50.412147 139787207567168 save_impl.py:90] Skipping full serialization of Keras layer <__main__.Residual_Block object at 0x7f21c64cf6d8>, because it is not built.\n",
      "W0501 13:35:50.828134 139787207567168 save_impl.py:90] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f21c64cf4e0>, because it is not built.\n",
      "W0501 13:35:50.829731 139787207567168 save_impl.py:90] Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f21c64cf9b0>, because it is not built.\n",
      "W0501 13:35:51.015313 139787207567168 deprecation.py:506] From /media/tim/Primary Storage/projects/machine_learning/ml_env/local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#saving custom model requires ckpt file type\n",
    "model.save('Custom_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Custom_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 3s 290us/sample - loss: 0.3814\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 2s 165us/sample - loss: 0.3610\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 2s 158us/sample - loss: 0.4043\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 2s 163us/sample - loss: 0.3693\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 2s 168us/sample - loss: 0.4053\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the custom model using sequential api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = Residual_Block(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal'),\n",
    "                      block1, block1, block1, block1, block1,\n",
    "                    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 3s 273us/sample - loss: 1.0089\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 2s 156us/sample - loss: 0.4475\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 2s 179us/sample - loss: 0.3910\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 2s 176us/sample - loss: 0.3871\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 2s 176us/sample - loss: 0.3772\n",
      "5160/5160 [==============================] - 1s 139us/sample - loss: 0.3841\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(x_test_scaled, Y_test)\n",
    "\n",
    "y_pred = model.predict(x_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses and Metrics based on model internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reconstructing_Regressor(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation='selu',\n",
    "                                         kernel_initializer='lecun_normal')\n",
    "                      for _ in range (5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    #issue tensorflow 26260\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        z = inputs\n",
    "        for layer in self.hidden:\n",
    "            z = layer(z)\n",
    "            \n",
    "        reconstruction = self.reconstruct(z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "                      \n",
    "        return self.out(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 5s 426us/sample - loss: 0.7044\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 2s 192us/sample - loss: 0.4049\n"
     ]
    }
   ],
   "source": [
    "model = Reconstructing_Regressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "history = model.fit(x_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 1s 148us/sample - loss: 0.3770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3769666276467863"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients with Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientTape.gradient can only be called once on non-persistent tapes.\n"
     ]
    }
   ],
   "source": [
    "#will only go through the recorded computations once (in reverse order)\n",
    "#tape is automatically removed after gradient is called\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with the tape persistently\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) \n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tape will only track operations that involve variables, thus a constant will not work\n",
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "    \n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can force gradient tape to watch tesnors thou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "    \n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### computing the individual gradients in regard to model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    " # second order partial derivatives  (not typically needed)   \n",
    "hessian = [hessian_tape.gradient(x, [w1, w2])\n",
    "          for x in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopping gradients from backproagating through some part of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example with softplus, pg 401\n",
    "x = tf.Variable(100.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = softplus_replicate(x)\n",
    "    \n",
    "tape.gradient(z, [x])   #not reproducing the id, however"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the gradients, returns both normal output and function that computes derivatives\n",
    "@tf.custom_gradient\n",
    "def improved_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1, softplus_gradients)\n",
    "\n",
    "#main output will still 'explode' bc of the exponential, workaround use: tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usage of tf.where to solve exploding\n",
    "def improved_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = improved_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# computing gradients w/ autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=l2_reg), \n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(x, y, batch_size=32):\n",
    "    idx = np.random.randint(len(x), size= batch_size)\n",
    "    return x[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = ' - '.join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    \n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 - loss: 0.0914 - mean_square: 825.0000"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "mean_loss = keras.metrics.Mean(name='loss')\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "\n",
    "for i in range(1, 50, + 1):\n",
    "    loss = 1 /i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'prettier' w/ progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pg 404, for indepth walk through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0501 13:36:30.407275 139787207567168 base_layer.py:1790] Layer dense_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.4578 - mean_absolute_error: 0.5861\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6600 - mean_absolute_error: 0.5273\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6538 - mean_absolute_error: 0.5264\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6593 - mean_absolute_error: 0.5257\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6301 - mean_absolute_error: 0.5146\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(x_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Custom Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tim/Primary Storage/projects/machine_learning/ml_env/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578086660bf542d28afa997352f66637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='All epochs', max=5.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tim/Primary Storage/projects/machine_learning/ml_env/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eefa89832154e2e999caeb9b111731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15839059b7b4abe88f8e015437c3f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baff95a13aac407e9677a0803b23ddde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7e504ebb9047228e2b50280aa0d378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f164b8a05eb446c9b16ff93ba58d469d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5/5', max=362.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm import tnrange\n",
    "    from collections import OrderedDict\n",
    "    with tnrange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with tnrange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(x_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))                    \n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow  functions and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7f21c4414da0>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert function into tf function\n",
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f21c6136e10>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_fn = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_fn.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_fn(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_fn is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function defs and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_fn.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_fn.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_fn.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_983499\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_fn.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing tf fn's to python fn's for computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0501 13:55:55.468075 139787207567168 def_function.py:586] 5 out of the last 5 calls to <function tf_cube at 0x7f21c61ea268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "W0501 13:55:55.474308 139787207567168 def_function.py:586] 6 out of the last 6 calls to <function tf_cube at 0x7f21c61ea268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # no trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.6234981  0.9465004 ]\n",
      "  [0.6747534  0.34780383]]\n",
      "\n",
      " [[0.66588044 0.76424825]\n",
      "  [0.80313575 0.02245963]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograph for control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#static loop\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic loop\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic loop w/ autograph\n",
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with variables and misc. resources w/ tf functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def tf__add_10(x):\\n  do_return = False\\n  retval_ = ag__.UndefinedReturnValue()\\n  with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\\n\\n    def get_state():\\n      return ()\\n\\n    def set_state(_):\\n      pass\\n\\n    def loop_body(iterates, x):\\n      i = iterates\\n      x += 1\\n      return x,\\n    x, = ag__.for_stmt(ag__.converted_call(tf.range, (10,), None, fscope), None, loop_body, get_state, set_state, (x,), ('x',), ())\\n    do_return = True\\n    retval_ = fscope.mark_return_value(x)\\n  do_return,\\n  return ag__.retval(retval_)\\n\""
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "tf.autograph.to_code(add_10.python_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf functions w/ tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4228 - my_mae: 0.4634 - val_loss: 0.4629 - val_my_mae: 0.4992\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.4114 - my_mae: 0.4552 - val_loss: 0.4495 - val_my_mae: 0.4721\n",
      "5160/5160 [==============================] - 0s 20us/sample - loss: 0.4044 - my_mae: 0.4587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4044472819843958, 0.4587218]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(x_valid_scaled, y_valid))\n",
    "model.evaluate(x_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)\n",
    "#to turn off the iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.625393867492676, 2.0625315]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(x_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(x_test_scaled[:64], Y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run eagerly\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.571150302886963, 2.0671072]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(x_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(x_test_scaled[:64], Y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 5.1151\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 1.6276\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.8834\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.6956\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.6378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21a8578320>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(x_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
