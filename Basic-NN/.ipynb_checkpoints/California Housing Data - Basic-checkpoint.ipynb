{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "\n",
    "#split the training for validation\n",
    "x_train, x_train_validation, y_train, y_train_validation = train_test_split(x_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.fit_transform(x_train_validation)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initalize randomness\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model - basic\n",
    "basic_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "basic_model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 1.6205 - val_loss: 0.8219\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.7162 - val_loss: 0.6754\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6356 - val_loss: 0.6238\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5989 - val_loss: 0.5946\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.5713 - val_loss: 0.5727\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5491 - val_loss: 0.5535\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.5301 - val_loss: 0.5388\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.5142 - val_loss: 0.5265\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.5004 - val_loss: 0.5149\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4883 - val_loss: 0.5048\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4786 - val_loss: 0.4989\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4697 - val_loss: 0.4923\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4621 - val_loss: 0.4854\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4556 - val_loss: 0.4814\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4497 - val_loss: 0.4772\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4443 - val_loss: 0.4735\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4397 - val_loss: 0.4677\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4354 - val_loss: 0.4649\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4315 - val_loss: 0.4628\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4281 - val_loss: 0.4602\n"
     ]
    }
   ],
   "source": [
    "#fit the model \n",
    "history = basic_model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_train_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the learning\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.4192\n"
     ]
    }
   ],
   "source": [
    "#mean squared error test \n",
    "mse_test = basic_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see prediction of the model \n",
    "sample_x = x_test[:3]\n",
    "predicted_y = basic_model.predict(sample_x)\n",
    "predicted_y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset randomness\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the wide and deep model\n",
    "input_ = keras.layers.Input(shape=x_train.shape[1:])\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden_2 = keras.layers.Dense(30, activation='relu')(hidden_1)\n",
    "concat = keras.layers.concatenate([input_, hidden_2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "wad_model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#view the model's archietecture\n",
    "wad_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model \n",
    "wad_model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 1.2390 - val_loss: 0.7015\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.6312 - val_loss: 0.6326\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5886 - val_loss: 0.5948\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5595 - val_loss: 0.5701\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5361 - val_loss: 0.5495\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5178 - val_loss: 0.5358\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5016 - val_loss: 0.5230\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4888 - val_loss: 0.5110\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4772 - val_loss: 0.4997\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4673 - val_loss: 0.4931\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4586 - val_loss: 0.4868\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4504 - val_loss: 0.4787\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4435 - val_loss: 0.4740\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4376 - val_loss: 0.4697\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4318 - val_loss: 0.4671\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4266 - val_loss: 0.4586\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4221 - val_loss: 0.4558\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4173 - val_loss: 0.4535\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4132 - val_loss: 0.4504\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4096 - val_loss: 0.4482\n"
     ]
    }
   ],
   "source": [
    "#run the model\n",
    "history_wad = wad_model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_train_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wad_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-69cc7a350285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#mean square error test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmse_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwad_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wad_model' is not defined"
     ]
    }
   ],
   "source": [
    "#mean square error test \n",
    "x_new = x_test[:3]\n",
    "mse_test = wad_model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38421202],\n",
       "       [1.9129956 ],\n",
       "       [3.6367598 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict on unseen data\n",
    "y_pred = wad_model.predict(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Subset Wide and Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            36          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "input_a = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_b = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_b)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_a, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "\n",
    "wad_d_model = keras.models.Model(inputs=[input_a, input_b], outputs=[output])\n",
    "\n",
    "wad_d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model \n",
    "wad_d_model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split up the data for the two different inputs\n",
    "#need to review the array management \n",
    "x_train_A, x_train_B = x_train[:, :5], x_train[:, 2:]\n",
    "x_valid_A, x_valid_B = x_valid[:, :5], x_valid[:, 2:]\n",
    "x_test_A, x_test_B = x_test[:, :5], x_test[:, 2:]\n",
    "x_new_A, x_new_B = x_test_A[:3], x_test_B[:3]\n",
    "\n",
    "\n",
    "#NTS keep the variable names to a minimum, only keep the names you need to use, and overwrite the others\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 1.8127 - val_loss: 0.8254\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.6852 - val_loss: 0.6504\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.5965 - val_loss: 0.5947\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5587 - val_loss: 0.5690\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5321 - val_loss: 0.5498\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5129 - val_loss: 0.5358\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.4959 - val_loss: 0.5248\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4837 - val_loss: 0.5142\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4734 - val_loss: 0.5056\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4646 - val_loss: 0.5011\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4571 - val_loss: 0.4964\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4507 - val_loss: 0.4930\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4456 - val_loss: 0.4872\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4422 - val_loss: 0.4850\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4386 - val_loss: 0.4846\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4361 - val_loss: 0.4773\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4326 - val_loss: 0.4747\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4296 - val_loss: 0.4742\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4278 - val_loss: 0.4773\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4259 - val_loss: 0.4720\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = wad_d_model.fit((x_train_A, x_train_B), y_train, epochs=20, validation_data=((x_valid_A, x_valid_B), y_train_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.4282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4282418046348779"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean squared error test\n",
    "mse_test = wad_d_model.evaluate((x_test_A, x_test_B), y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25735503],\n",
       "       [2.0114598 ],\n",
       "       [3.7038774 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look a the predictions\n",
    "y_pred = wad_d_model.predict((x_new_A, x_new_B))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep with Auxiliary output for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize \n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A,hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(hidden2)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           930         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            31          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,202\n",
      "Trainable params: 1,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss=[\"mse\",\"mse\"], loss_weights=[0.9,0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 2.8146 - main_output_loss: 2.5852 - aux_output_loss: 4.8688 - val_loss: 1.5604 - val_main_output_loss: 1.3078 - val_aux_output_loss: 3.8320\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 1.3702 - main_output_loss: 1.1652 - aux_output_loss: 3.2155 - val_loss: 1.2490 - val_main_output_loss: 1.1156 - val_aux_output_loss: 2.4485\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 1.1474 - main_output_loss: 1.0346 - aux_output_loss: 2.1627 - val_loss: 1.0767 - val_main_output_loss: 0.9985 - val_aux_output_loss: 1.7795\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 1.0094 - main_output_loss: 0.9378 - aux_output_loss: 1.6529 - val_loss: 0.9636 - val_main_output_loss: 0.9083 - val_aux_output_loss: 1.4603\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.9020 - main_output_loss: 0.8472 - aux_output_loss: 1.3962 - val_loss: 0.8779 - val_main_output_loss: 0.8327 - val_aux_output_loss: 1.2840\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.8157 - main_output_loss: 0.7691 - aux_output_loss: 1.2342 - val_loss: 0.8179 - val_main_output_loss: 0.7783 - val_aux_output_loss: 1.1735\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.7485 - main_output_loss: 0.7063 - aux_output_loss: 1.1285 - val_loss: 0.7814 - val_main_output_loss: 0.7471 - val_aux_output_loss: 1.0888\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 79us/sample - loss: 0.7017 - main_output_loss: 0.6634 - aux_output_loss: 1.0458 - val_loss: 0.7553 - val_main_output_loss: 0.7252 - val_aux_output_loss: 1.0262\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.6700 - main_output_loss: 0.6351 - aux_output_loss: 0.9842 - val_loss: 0.7391 - val_main_output_loss: 0.7120 - val_aux_output_loss: 0.9822\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.6488 - main_output_loss: 0.6164 - aux_output_loss: 0.9394 - val_loss: 0.7289 - val_main_output_loss: 0.7048 - val_aux_output_loss: 0.9448\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.6324 - main_output_loss: 0.6025 - aux_output_loss: 0.9021 - val_loss: 0.7192 - val_main_output_loss: 0.6971 - val_aux_output_loss: 0.9175\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 82us/sample - loss: 0.6195 - main_output_loss: 0.5914 - aux_output_loss: 0.8726 - val_loss: 0.7114 - val_main_output_loss: 0.6912 - val_aux_output_loss: 0.8927\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.6096 - main_output_loss: 0.5831 - aux_output_loss: 0.8471 - val_loss: 0.7035 - val_main_output_loss: 0.6847 - val_aux_output_loss: 0.8726\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.6012 - main_output_loss: 0.5762 - aux_output_loss: 0.8269 - val_loss: 0.7036 - val_main_output_loss: 0.6867 - val_aux_output_loss: 0.8557\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5931 - main_output_loss: 0.5693 - aux_output_loss: 0.8052 - val_loss: 0.6959 - val_main_output_loss: 0.6795 - val_aux_output_loss: 0.8419\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.5873 - main_output_loss: 0.5650 - aux_output_loss: 0.7904 - val_loss: 0.6899 - val_main_output_loss: 0.6746 - val_aux_output_loss: 0.8262\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.5809 - main_output_loss: 0.5594 - aux_output_loss: 0.7734 - val_loss: 0.6847 - val_main_output_loss: 0.6704 - val_aux_output_loss: 0.8134\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 80us/sample - loss: 0.5757 - main_output_loss: 0.5553 - aux_output_loss: 0.7599 - val_loss: 0.6816 - val_main_output_loss: 0.6680 - val_aux_output_loss: 0.8032\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5709 - main_output_loss: 0.5512 - aux_output_loss: 0.7480 - val_loss: 0.6821 - val_main_output_loss: 0.6697 - val_aux_output_loss: 0.7926\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5655 - main_output_loss: 0.5468 - aux_output_loss: 0.7343 - val_loss: 0.6792 - val_main_output_loss: 0.6675 - val_aux_output_loss: 0.7846\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history = model.fit([x_train_A, x_train_B], [y_train, y_train], epochs=20, validation_data=([x_valid_A, x_valid_B], [y_train_validation, y_train_validation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 26us/sample - loss: 0.5789 - main_output_loss: 0.5643 - aux_output_loss: 0.7182\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model's losses\n",
    "total_loss, main_output_loss, aux_output_loss = model.evaluate([x_test_A, x_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the predictions the model makes\n",
    "y_pred_main, y_pred_aux = model.predict([x_new_A, x_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub classing Wide and Deep model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to make the wide a reusable method\n",
    "\n",
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss=\"mse\", loss_weights=[0.9,0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 80us/sample - loss: 2.2719 - output_1_loss: 2.1554 - output_2_loss: 3.3117 - val_loss: 1.1546 - val_output_1_loss: 1.0258 - val_output_2_loss: 2.3113\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.9891 - output_1_loss: 0.8653 - output_2_loss: 2.1062 - val_loss: 0.8800 - val_output_1_loss: 0.7740 - val_output_2_loss: 1.8321\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.8320 - output_1_loss: 0.7303 - output_2_loss: 1.7468 - val_loss: 0.7917 - val_output_1_loss: 0.6982 - val_output_2_loss: 1.6319\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.7658 - output_1_loss: 0.6760 - output_2_loss: 1.5726 - val_loss: 0.7434 - val_output_1_loss: 0.6573 - val_output_2_loss: 1.5168\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.7223 - output_1_loss: 0.6394 - output_2_loss: 1.4683 - val_loss: 0.7089 - val_output_1_loss: 0.6277 - val_output_2_loss: 1.4376\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.6909 - output_1_loss: 0.6132 - output_2_loss: 1.3901 - val_loss: 0.6823 - val_output_1_loss: 0.6045 - val_output_2_loss: 1.3810\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 76us/sample - loss: 0.6636 - output_1_loss: 0.5894 - output_2_loss: 1.3330 - val_loss: 0.6608 - val_output_1_loss: 0.5860 - val_output_2_loss: 1.3320\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.6406 - output_1_loss: 0.5691 - output_2_loss: 1.2833 - val_loss: 0.6410 - val_output_1_loss: 0.5687 - val_output_2_loss: 1.2902\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.6199 - output_1_loss: 0.5507 - output_2_loss: 1.2416 - val_loss: 0.6240 - val_output_1_loss: 0.5540 - val_output_2_loss: 1.2524\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.6019 - output_1_loss: 0.5351 - output_2_loss: 1.2026 - val_loss: 0.6110 - val_output_1_loss: 0.5433 - val_output_2_loss: 1.2194\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "history = model.fit((x_train_A, x_train_B), (y_train, y_train), epochs=10, validation_data=((x_valid_A, x_valid_B), (y_train_validation, y_train_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see predictions\n",
    "y_pred_main, y_pred_aux = model.predict((x_new_A, x_new_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes a new model will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 2.0125 - val_loss: 0.9651\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.8614 - val_loss: 0.7062\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.7026 - val_loss: 0.6421\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.6411 - val_loss: 0.6068\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5950 - val_loss: 0.5737\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5574 - val_loss: 0.5513\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5255 - val_loss: 0.5314\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4995 - val_loss: 0.5122\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4781 - val_loss: 0.4971\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4608 - val_loss: 0.4859\n",
      "5160/5160 [==============================] - 0s 28us/sample - loss: 0.4378\n"
     ]
    }
   ],
   "source": [
    "#compile and train the model\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_train_validation))\n",
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save the model\n",
    "model.save('Cali-housing/3_dense_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load the model\n",
    "model = keras.models.load_model('Cali-housing/3_dense_nn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67456627],\n",
       "       [1.6089154 ],\n",
       "       [5.2064805 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict on unseen\n",
    "model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model's weights\n",
    "model.save_weights('Cali-housing/3_dense_nn_weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd2a9584a58>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the model's weights\n",
    "model.load_weights('Cali-housing/3_dense_nn_weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.4471\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4364\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4278\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4210\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4154\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4110\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4072\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4041\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4015\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3991\n"
     ]
    }
   ],
   "source": [
    "#checkpoint saving\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"3_dense_nn.h5\")\n",
    "#saves the model at particular intervals during training\n",
    "history = model.fit(x_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to save only the best model, if using a validation test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3971 - val_loss: 0.4413\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3952 - val_loss: 0.4370\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3934 - val_loss: 0.4344\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3920 - val_loss: 0.4368\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3902 - val_loss: 0.4332\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3887 - val_loss: 0.4336\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3873 - val_loss: 0.4335\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3860 - val_loss: 0.4293\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3848 - val_loss: 0.4297\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3835 - val_loss: 0.4300\n"
     ]
    }
   ],
   "source": [
    "#saving the best model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"3_dense_nn.h5\", save_best_only=True)\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_train_validation), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('3_dense_nn.h5') #saves the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3826 - val_loss: 0.4321\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 90us/sample - loss: 0.3815 - val_loss: 0.4284\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3804 - val_loss: 0.4266\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3796 - val_loss: 0.4295\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3783 - val_loss: 0.4266\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3774 - val_loss: 0.4270\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3765 - val_loss: 0.4274\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3756 - val_loss: 0.4237\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3747 - val_loss: 0.4246\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3738 - val_loss: 0.4252\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3730 - val_loss: 0.4222\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3721 - val_loss: 0.4258\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 79us/sample - loss: 0.3713 - val_loss: 0.4230\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3708 - val_loss: 0.4244\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3700 - val_loss: 0.4232\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3694 - val_loss: 0.4210\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3689 - val_loss: 0.4214\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3677 - val_loss: 0.4207\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3671 - val_loss: 0.4222\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3666 - val_loss: 0.4212\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3657 - val_loss: 0.4219\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3650 - val_loss: 0.4221\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3645 - val_loss: 0.4204\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3637 - val_loss: 0.4180\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3629 - val_loss: 0.4200\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3625 - val_loss: 0.4191\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3615 - val_loss: 0.4182\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3609 - val_loss: 0.4188\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 0.3604 - val_loss: 0.4218\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3599 - val_loss: 0.4201\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3593 - val_loss: 0.4181\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3590 - val_loss: 0.4180\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3582 - val_loss: 0.4163\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3579 - val_loss: 0.4158\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3571 - val_loss: 0.4154\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3567 - val_loss: 0.4156\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3562 - val_loss: 0.4186\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3556 - val_loss: 0.4171\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3548 - val_loss: 0.4179\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3548 - val_loss: 0.4167\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3542 - val_loss: 0.4158\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3539 - val_loss: 0.4161\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3532 - val_loss: 0.4149\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3527 - val_loss: 0.4190\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3523 - val_loss: 0.4160\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3518 - val_loss: 0.4160\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3507 - val_loss: 0.4130\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3508 - val_loss: 0.4135\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3502 - val_loss: 0.4160\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3498 - val_loss: 0.4132\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3495 - val_loss: 0.4131\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3488 - val_loss: 0.4155\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3486 - val_loss: 0.4151\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3479 - val_loss: 0.4158\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3475 - val_loss: 0.4142\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3471 - val_loss: 0.4155\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3468 - val_loss: 0.4152\n"
     ]
    }
   ],
   "source": [
    "#stops training when no progress is being made on the validation test set\n",
    "#patience = number of iterations till stopped\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_train_validation), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallBack(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"]/ logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "10240/11610 [=========================>....] - ETA: 0s - loss: 0.3439\n",
      "val/train: 1.19\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3508 - val_loss: 0.4180\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallBack()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1, validation_data=(x_valid, y_train_validation), callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "root_logdir = os.path.join(os.curdir, \"tensorboard_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4017efb3e53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_logdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_run_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrun_logdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-4017efb3e53d>\u001b[0m in \u001b[0;36mget_run_logdir\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_%Y_%m_%d-%H_%M_%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_logdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrun_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_run_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#create a log directory and save the current\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear training session and randomize\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and compile model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 1.8423 - val_loss: 0.8104\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.6876 - val_loss: 0.6229\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5954 - val_loss: 0.5798\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5553 - val_loss: 0.5521\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5268 - val_loss: 0.5278\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.5049 - val_loss: 0.5132\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4852 - val_loss: 0.5013\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4706 - val_loss: 0.4889\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4576 - val_loss: 0.4775\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4476 - val_loss: 0.4715\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4388 - val_loss: 0.4680\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4313 - val_loss: 0.4606\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4252 - val_loss: 0.4563\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 79us/sample - loss: 0.4198 - val_loss: 0.4547\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.4152 - val_loss: 0.4535\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4109 - val_loss: 0.4465\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4073 - val_loss: 0.4425\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.4037 - val_loss: 0.4416\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 88us/sample - loss: 0.4003 - val_loss: 0.4388\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3974 - val_loss: 0.4363\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3945 - val_loss: 0.4350\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3919 - val_loss: 0.4334\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3893 - val_loss: 0.4315\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3869 - val_loss: 0.4284\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3846 - val_loss: 0.4275\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3825 - val_loss: 0.4262\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3802 - val_loss: 0.4242\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3781 - val_loss: 0.4233\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3761 - val_loss: 0.4236\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3742 - val_loss: 0.4226\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_train_validation), callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the tensorboard it needs to be started as a seperate server, which one option can be through the terminal\n",
    "\n",
    "$ tensorboard --logdir=./tensorboard_logs --port=6006\n",
    "\n",
    "it can also be ran within the jupyter notebook (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9ab452478d4a3f66\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9ab452478d4a3f66\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#running tensorboard within the notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./tensorboard_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tensorboard_logs/run_2020_04_22-16_49_44'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running the model with the tensorboard active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and compile another model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 5.6341 - val_loss: 1.3210\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 1.2704 - val_loss: 1.1065\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.9370 - val_loss: 0.8001\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.8854 - val_loss: 0.8935\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.9501 - val_loss: 1.0161\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.8283 - val_loss: 0.7035\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.8095 - val_loss: 0.8388\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 1.1857 - val_loss: 1.0425\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.8920 - val_loss: 0.6994\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.2295 - val_loss: 1.1450\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.8992 - val_loss: 0.6986\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.7697 - val_loss: 0.8104\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.7375 - val_loss: 0.6983\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.9825 - val_loss: 1.0198\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.9653 - val_loss: 0.9341\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.9008 - val_loss: 0.8967\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.7838 - val_loss: 0.6887\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.9960 - val_loss: 1.1082\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.7887 - val_loss: 0.7876\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.5706 - val_loss: 0.6201\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.5192 - val_loss: 0.6520\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4971 - val_loss: 0.5690\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4815 - val_loss: 0.5060\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 1s 79us/sample - loss: 0.4678 - val_loss: 0.5762\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4490 - val_loss: 0.4888\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4348 - val_loss: 0.5215\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.4377 - val_loss: 0.4746\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4353 - val_loss: 0.4709\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4209 - val_loss: 0.4744\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.4441 - val_loss: 0.5117\n"
     ]
    }
   ],
   "source": [
    "#create tensorboard callback\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_train_validation), callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard will review both models, showing the learning curves of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extra tb help\n",
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_and_randomize():\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_and_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that builds models\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    #input layer\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    #hidden layers\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    #output layer\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    #optimizer \n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    #compile\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create regressor based on the model\n",
    "keras_regressor = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "#will use the default hyperparameters since not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 1.1399 - val_loss: 0.8726\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.7393 - val_loss: 0.6014\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5374 - val_loss: 0.5220\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4796 - val_loss: 0.4980\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4536 - val_loss: 0.4806\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4373 - val_loss: 0.4698\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4256 - val_loss: 0.4662\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4178 - val_loss: 0.4550\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4114 - val_loss: 0.4510\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.4060 - val_loss: 0.4489\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4018 - val_loss: 0.4434\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3978 - val_loss: 0.4446\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3943 - val_loss: 0.4406\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3915 - val_loss: 0.4417\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3888 - val_loss: 0.4391\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3862 - val_loss: 0.4346\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3842 - val_loss: 0.4341\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3815 - val_loss: 0.4321\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3797 - val_loss: 0.4326\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3777 - val_loss: 0.4318\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3763 - val_loss: 0.4323\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3742 - val_loss: 0.4326\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3729 - val_loss: 0.4298\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3718 - val_loss: 0.4274\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3701 - val_loss: 0.4285\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3689 - val_loss: 0.4280\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3674 - val_loss: 0.4246\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3666 - val_loss: 0.4274\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3649 - val_loss: 0.4292\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3645 - val_loss: 0.4261\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3636 - val_loss: 0.4242\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3626 - val_loss: 0.4241\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3616 - val_loss: 0.4220\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3613 - val_loss: 0.4221\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3600 - val_loss: 0.4212\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3593 - val_loss: 0.4206\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3583 - val_loss: 0.4237\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3578 - val_loss: 0.4206\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3563 - val_loss: 0.4216\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3567 - val_loss: 0.4201\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3553 - val_loss: 0.4192\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3552 - val_loss: 0.4199\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3539 - val_loss: 0.4181\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3533 - val_loss: 0.4234\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3529 - val_loss: 0.4188\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3522 - val_loss: 0.4190\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3510 - val_loss: 0.4160\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3515 - val_loss: 0.4156\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3506 - val_loss: 0.4192\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3506 - val_loss: 0.4165\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3501 - val_loss: 0.4154\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3495 - val_loss: 0.4157\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3485 - val_loss: 0.4149\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3479 - val_loss: 0.4174\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3475 - val_loss: 0.4166\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3472 - val_loss: 0.4161\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3474 - val_loss: 0.4186\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3464 - val_loss: 0.4169\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3458 - val_loss: 0.4138\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3451 - val_loss: 0.4136\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3456 - val_loss: 0.4137\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3441 - val_loss: 0.4116\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3443 - val_loss: 0.4129\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3443 - val_loss: 0.4120\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3433 - val_loss: 0.4131\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3429 - val_loss: 0.4115\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3431 - val_loss: 0.4126\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3416 - val_loss: 0.4086\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3409 - val_loss: 0.4142\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3412 - val_loss: 0.4125\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3400 - val_loss: 0.4067\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3404 - val_loss: 0.4100\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3394 - val_loss: 0.4101\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3396 - val_loss: 0.4111\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3388 - val_loss: 0.4113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3390 - val_loss: 0.4110\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3390 - val_loss: 0.4105\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3391 - val_loss: 0.4099\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3399 - val_loss: 0.4170\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3418 - val_loss: 0.4099\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3372 - val_loss: 0.4107\n",
      "5160/5160 [==============================] - 0s 14us/sample - loss: 0.3812\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "keras_regressor.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_train_validation),\n",
    "                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "#mean square error test\n",
    "mse_test = keras_regressor.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7458043],\n",
       "       [1.8752358],\n",
       "       [4.4436855]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see predictions \n",
    "x_new = x_test[:3]\n",
    "y_pred = model.predict(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_and_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized search\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#set the parameters\n",
    "parameters_distributions = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "\r",
      "  32/7740 [..............................] - ETA: 31s - loss: 6.7379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 71us/sample - loss: 3.5574 - val_loss: 1.7730\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.3316 - val_loss: 0.9041\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8573 - val_loss: 0.7097\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.7344 - val_loss: 0.6515\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6943 - val_loss: 0.6285\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6682 - val_loss: 0.6101\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6494 - val_loss: 0.5957\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6408 - val_loss: 0.5877\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6256 - val_loss: 0.5800\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6149 - val_loss: 0.5700\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6058 - val_loss: 0.5623\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5961 - val_loss: 0.5522\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.5905 - val_loss: 0.5494\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5797 - val_loss: 0.5418\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5764 - val_loss: 0.5350\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5745 - val_loss: 0.5327\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5635 - val_loss: 0.5284\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5639 - val_loss: 0.5240\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5608 - val_loss: 0.5227\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5562 - val_loss: 0.5221\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5528 - val_loss: 0.5195\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5497 - val_loss: 0.5173\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5466 - val_loss: 0.5141\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5477 - val_loss: 0.5163\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5416 - val_loss: 0.5112\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5432 - val_loss: 0.5109\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.5390 - val_loss: 0.5100\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5417 - val_loss: 0.5106\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5380 - val_loss: 0.5092\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.5356 - val_loss: 0.5085\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5382 - val_loss: 0.5094\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5334 - val_loss: 0.5078\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5364 - val_loss: 0.5088\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5339 - val_loss: 0.5076\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5298 - val_loss: 0.5047\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.5348 - val_loss: 0.5067\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5325 - val_loss: 0.5053\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5310 - val_loss: 0.5061\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.5313 - val_loss: 0.5047\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5317 - val_loss: 0.5074\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.5300 - val_loss: 0.5048\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5310 - val_loss: 0.5050\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5268 - val_loss: 0.5043\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5330 - val_loss: 0.5059\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5261 - val_loss: 0.5040\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5312 - val_loss: 0.5027\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5299 - val_loss: 0.5029\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5302 - val_loss: 0.5040\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.5288 - val_loss: 0.5035\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5295 - val_loss: 0.5062\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5257 - val_loss: 0.5030\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5303 - val_loss: 0.5033\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5294 - val_loss: 0.5041\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5287 - val_loss: 0.5046\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5284 - val_loss: 0.5049\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5269 - val_loss: 0.5043\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5393\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=  23.9s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 61us/sample - loss: 3.5541 - val_loss: 2.0118\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.4756 - val_loss: 1.1404\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 1.0159 - val_loss: 0.8998\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.8738 - val_loss: 0.8015\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8034 - val_loss: 0.7462\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7549 - val_loss: 0.7114\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7166 - val_loss: 0.6888\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6854 - val_loss: 0.6751\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6593 - val_loss: 0.6667\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6375 - val_loss: 0.6633\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6190 - val_loss: 0.6611\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6033 - val_loss: 0.6606\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5898 - val_loss: 0.6619\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5783 - val_loss: 0.6629\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5684 - val_loss: 0.6640\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5597 - val_loss: 0.6667\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5524 - val_loss: 0.6675\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5459 - val_loss: 0.6689\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5402 - val_loss: 0.6686\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5352 - val_loss: 0.6695\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5310 - val_loss: 0.6700\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5271 - val_loss: 0.6709\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 1.0053\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=   7.7s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 3.2309 - val_loss: 1.2952\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.9653 - val_loss: 0.6314\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6144 - val_loss: 0.5144\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5510 - val_loss: 0.4967\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5343 - val_loss: 0.4949\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5342 - val_loss: 0.4953\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5322 - val_loss: 0.4951\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5310 - val_loss: 0.4947\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5310 - val_loss: 0.4950\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5318 - val_loss: 0.4961\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5335 - val_loss: 0.4954\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5310 - val_loss: 0.4954\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5319 - val_loss: 0.4976\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5308 - val_loss: 0.4962\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5309 - val_loss: 0.4974\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5303 - val_loss: 0.4957\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5289 - val_loss: 0.4955\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5320 - val_loss: 0.4960\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5339\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=15, total=   6.8s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 1.4568 - val_loss: 0.7340\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6432 - val_loss: 0.5576\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5927 - val_loss: 0.5401\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5738 - val_loss: 0.5119\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6437 - val_loss: 0.8450\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6352 - val_loss: 0.9208\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 2.0469 - val_loss: 2.2663\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.0236 - val_loss: 3.3407\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 2.0421 - val_loss: 19.8434\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 10.1616 - val_loss: 61.9449\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 37.8901 - val_loss: 272.8419\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 252.6434 - val_loss: 1022.3383\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 492.7466 - val_loss: 4272.9426\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 8999.3402 - val_loss: 16403.7324\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 4267.3509\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   4.6s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 1.1508 - val_loss: 0.6914\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5340 - val_loss: 0.6744\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5226 - val_loss: 0.6710\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5148 - val_loss: 0.6480\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5125 - val_loss: 0.6430\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5082 - val_loss: 0.6332\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5050 - val_loss: 0.6292\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5058 - val_loss: 0.6263\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5057 - val_loss: 0.6198\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5035 - val_loss: 0.6445\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5045 - val_loss: 0.6204\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5023 - val_loss: 0.6288\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5023 - val_loss: 0.6456\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5022 - val_loss: 0.6408\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5031 - val_loss: 0.6364\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5027 - val_loss: 0.6607\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5022 - val_loss: 0.6562\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5031 - val_loss: 0.6542\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5014 - val_loss: 0.6273\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.9160\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   6.4s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.4056 - val_loss: 0.7531\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.9238 - val_loss: 1.8905\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 2.8216 - val_loss: 3.0460\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 4.9607 - val_loss: 7.0427\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 11.6930 - val_loss: 12.6632\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 16.1341 - val_loss: 26.0205\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 48.1242 - val_loss: 47.8992\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 119.1232 - val_loss: 91.8658\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 266.2211 - val_loss: 177.2861\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 489.5452 - val_loss: 341.6274\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 370.8847 - val_loss: 647.5556\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 65.7429\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=   3.8s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 2.4669 - val_loss: 1.3566\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.1144 - val_loss: 0.8854\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8083 - val_loss: 0.7570\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7204 - val_loss: 0.7050\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6790 - val_loss: 0.6755\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6502 - val_loss: 0.6519\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6261 - val_loss: 0.6324\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6055 - val_loss: 0.6166\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5870 - val_loss: 0.6008\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5703 - val_loss: 0.5884\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5549 - val_loss: 0.5755\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5409 - val_loss: 0.5639\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5281 - val_loss: 0.5545\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5158 - val_loss: 0.5445\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5054 - val_loss: 0.5364\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4950 - val_loss: 0.5307\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4859 - val_loss: 0.5212\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4775 - val_loss: 0.5156\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4697 - val_loss: 0.5098\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4622 - val_loss: 0.5027\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4557 - val_loss: 0.4990\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4498 - val_loss: 0.4932\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4440 - val_loss: 0.4900\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4388 - val_loss: 0.4853\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4339 - val_loss: 0.4816\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4296 - val_loss: 0.4790\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4254 - val_loss: 0.4748\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4218 - val_loss: 0.4725\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4183 - val_loss: 0.4684\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4150 - val_loss: 0.4667\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4119 - val_loss: 0.4638\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4089 - val_loss: 0.4617\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4062 - val_loss: 0.4589\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4036 - val_loss: 0.4576\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4012 - val_loss: 0.4547\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3985 - val_loss: 0.4531\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3968 - val_loss: 0.4511\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3945 - val_loss: 0.4510\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3927 - val_loss: 0.4484\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3908 - val_loss: 0.4473\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3891 - val_loss: 0.4452\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3873 - val_loss: 0.4442\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3856 - val_loss: 0.4432\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3840 - val_loss: 0.4413\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3825 - val_loss: 0.4409\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3811 - val_loss: 0.4393\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3797 - val_loss: 0.4389\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3781 - val_loss: 0.4378\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3770 - val_loss: 0.4365\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3759 - val_loss: 0.4353\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3746 - val_loss: 0.4348\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3734 - val_loss: 0.4346\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3722 - val_loss: 0.4330\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3713 - val_loss: 0.4315\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3700 - val_loss: 0.4310\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3691 - val_loss: 0.4318\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3682 - val_loss: 0.4310\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3670 - val_loss: 0.4303\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3663 - val_loss: 0.4291\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3654 - val_loss: 0.4291\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3644 - val_loss: 0.4281\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3634 - val_loss: 0.4277\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3628 - val_loss: 0.4269\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3619 - val_loss: 0.4258\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3610 - val_loss: 0.4258\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3603 - val_loss: 0.4251\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3596 - val_loss: 0.4247\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3588 - val_loss: 0.4249\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3579 - val_loss: 0.4250\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3574 - val_loss: 0.4233\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3565 - val_loss: 0.4240\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3560 - val_loss: 0.4232\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3553 - val_loss: 0.4229\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3544 - val_loss: 0.4226\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3541 - val_loss: 0.4223\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3535 - val_loss: 0.4214\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3528 - val_loss: 0.4207\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3520 - val_loss: 0.4210\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3515 - val_loss: 0.4208\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3509 - val_loss: 0.4208\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3504 - val_loss: 0.4199\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3499 - val_loss: 0.4194\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3493 - val_loss: 0.4196\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3488 - val_loss: 0.4196\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3482 - val_loss: 0.4186\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3476 - val_loss: 0.4194\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3469 - val_loss: 0.4189\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3468 - val_loss: 0.4185\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3462 - val_loss: 0.4184\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3456 - val_loss: 0.4183\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3453 - val_loss: 0.4180\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3447 - val_loss: 0.4178\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3443 - val_loss: 0.4178\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3439 - val_loss: 0.4175\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3432 - val_loss: 0.4175\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3429 - val_loss: 0.4169\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3426 - val_loss: 0.4170\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3420 - val_loss: 0.4168\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3413 - val_loss: 0.4174\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3413 - val_loss: 0.4168\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3647\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  36.8s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 2.7764 - val_loss: 1.5612\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.1021 - val_loss: 1.0303\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8031 - val_loss: 0.8458\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7045 - val_loss: 0.7599\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6578 - val_loss: 0.7078\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6260 - val_loss: 0.6711\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6005 - val_loss: 0.6374\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5789 - val_loss: 0.6153\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5598 - val_loss: 0.5919\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5433 - val_loss: 0.5775\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5284 - val_loss: 0.5601\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5151 - val_loss: 0.5469\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5037 - val_loss: 0.5377\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4931 - val_loss: 0.5279\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4838 - val_loss: 0.5193\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4755 - val_loss: 0.5140\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4679 - val_loss: 0.5060\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4611 - val_loss: 0.5027\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4550 - val_loss: 0.4966\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4492 - val_loss: 0.4904\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4443 - val_loss: 0.4882\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4396 - val_loss: 0.4837\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4353 - val_loss: 0.4798\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4313 - val_loss: 0.4771\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4276 - val_loss: 0.4730\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4240 - val_loss: 0.4722\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4209 - val_loss: 0.4682\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4180 - val_loss: 0.4662\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4152 - val_loss: 0.4626\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4125 - val_loss: 0.4615\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4099 - val_loss: 0.4596\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4076 - val_loss: 0.4568\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4052 - val_loss: 0.4540\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4029 - val_loss: 0.4541\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4010 - val_loss: 0.4507\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3988 - val_loss: 0.4481\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3971 - val_loss: 0.4472\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3950 - val_loss: 0.4466\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3934 - val_loss: 0.4449\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3917 - val_loss: 0.4439\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3902 - val_loss: 0.4425\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3886 - val_loss: 0.4418\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3871 - val_loss: 0.4401\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3856 - val_loss: 0.4384\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3844 - val_loss: 0.4372\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3830 - val_loss: 0.4359\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3818 - val_loss: 0.4357\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3805 - val_loss: 0.4340\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3793 - val_loss: 0.4331\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3783 - val_loss: 0.4323\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3772 - val_loss: 0.4318\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3762 - val_loss: 0.4327\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3750 - val_loss: 0.4302\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3742 - val_loss: 0.4290\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3732 - val_loss: 0.4293\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3722 - val_loss: 0.4287\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3713 - val_loss: 0.4276\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3706 - val_loss: 0.4287\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3697 - val_loss: 0.4278\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3689 - val_loss: 0.4270\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 131us/sample - loss: 0.3680 - val_loss: 0.4284\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3670 - val_loss: 0.4255\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3666 - val_loss: 0.4262\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3658 - val_loss: 0.4245\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3651 - val_loss: 0.4256\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3644 - val_loss: 0.4255\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3637 - val_loss: 0.4248\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3631 - val_loss: 0.4251\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3625 - val_loss: 0.4241\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3617 - val_loss: 0.4234\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3610 - val_loss: 0.4257\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3605 - val_loss: 0.4240\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3600 - val_loss: 0.4228\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3594 - val_loss: 0.4218\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3589 - val_loss: 0.4222\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3583 - val_loss: 0.4213\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3578 - val_loss: 0.4223\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3572 - val_loss: 0.4228\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3567 - val_loss: 0.4213\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3563 - val_loss: 0.4208\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3557 - val_loss: 0.4214\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3553 - val_loss: 0.4204\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3548 - val_loss: 0.4211\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3544 - val_loss: 0.4195\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3540 - val_loss: 0.4191\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3535 - val_loss: 0.4193\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3527 - val_loss: 0.4215\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3526 - val_loss: 0.4189\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3522 - val_loss: 0.4192\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3516 - val_loss: 0.4196\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3513 - val_loss: 0.4190\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3508 - val_loss: 0.4190\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3505 - val_loss: 0.4181\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3500 - val_loss: 0.4176\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3497 - val_loss: 0.4173\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3491 - val_loss: 0.4184\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3489 - val_loss: 0.4177\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3483 - val_loss: 0.4184\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3481 - val_loss: 0.4168\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3478 - val_loss: 0.4177\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3772\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  43.6s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 2.8244 - val_loss: 1.3353\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.1397 - val_loss: 0.8952\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.8399 - val_loss: 0.7908\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7621 - val_loss: 0.7440\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.7220 - val_loss: 0.7121\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6927 - val_loss: 0.6881\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6684 - val_loss: 0.6678\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6467 - val_loss: 0.6509\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6270 - val_loss: 0.6332\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6087 - val_loss: 0.6202\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5914 - val_loss: 0.6042\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5756 - val_loss: 0.5923\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5606 - val_loss: 0.5819\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5470 - val_loss: 0.5709\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5345 - val_loss: 0.5592\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5229 - val_loss: 0.5499\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5122 - val_loss: 0.5411\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5021 - val_loss: 0.5348\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4932 - val_loss: 0.5249\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4848 - val_loss: 0.5192\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4772 - val_loss: 0.5132\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4702 - val_loss: 0.5073\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4636 - val_loss: 0.5007\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4577 - val_loss: 0.4981\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4521 - val_loss: 0.4926\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4470 - val_loss: 0.4891\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4423 - val_loss: 0.4849\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4379 - val_loss: 0.4807\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4338 - val_loss: 0.4766\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4300 - val_loss: 0.4739\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4265 - val_loss: 0.4712\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4233 - val_loss: 0.4684\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4202 - val_loss: 0.4655\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4172 - val_loss: 0.4647\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4149 - val_loss: 0.4613\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4123 - val_loss: 0.4583\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4099 - val_loss: 0.4573\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4079 - val_loss: 0.4559\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4057 - val_loss: 0.4554\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4039 - val_loss: 0.4519\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4019 - val_loss: 0.4506\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4000 - val_loss: 0.4504\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3983 - val_loss: 0.4482\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3965 - val_loss: 0.4481\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3951 - val_loss: 0.4450\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3935 - val_loss: 0.4450\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3921 - val_loss: 0.4441\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3909 - val_loss: 0.4429\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3895 - val_loss: 0.4420\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3883 - val_loss: 0.4410\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3870 - val_loss: 0.4401\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3860 - val_loss: 0.4400\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3849 - val_loss: 0.4387\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3837 - val_loss: 0.4386\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3826 - val_loss: 0.4387\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3817 - val_loss: 0.4383\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3807 - val_loss: 0.4361\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3797 - val_loss: 0.4363\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3789 - val_loss: 0.4358\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3781 - val_loss: 0.4353\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3774 - val_loss: 0.4340\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3763 - val_loss: 0.4336\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3755 - val_loss: 0.4338\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3746 - val_loss: 0.4327\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3740 - val_loss: 0.4332\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3734 - val_loss: 0.4321\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3726 - val_loss: 0.4319\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3719 - val_loss: 0.4321\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3711 - val_loss: 0.4326\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3707 - val_loss: 0.4304\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3697 - val_loss: 0.4313\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3693 - val_loss: 0.4300\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3685 - val_loss: 0.4309\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3681 - val_loss: 0.4293\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3675 - val_loss: 0.4283\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3668 - val_loss: 0.4295\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3662 - val_loss: 0.4291\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3656 - val_loss: 0.4297\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3649 - val_loss: 0.4278\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3646 - val_loss: 0.4280\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3639 - val_loss: 0.4273\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3633 - val_loss: 0.4277\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3629 - val_loss: 0.4274\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3623 - val_loss: 0.4268\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3619 - val_loss: 0.4263\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3613 - val_loss: 0.4268\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3608 - val_loss: 0.4271\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3603 - val_loss: 0.4271\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3599 - val_loss: 0.4259\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3594 - val_loss: 0.4260\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3591 - val_loss: 0.4255\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3583 - val_loss: 0.4255\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3580 - val_loss: 0.4261\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3576 - val_loss: 0.4246\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3571 - val_loss: 0.4242\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3568 - val_loss: 0.4244\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3563 - val_loss: 0.4244\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3557 - val_loss: 0.4236\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3555 - val_loss: 0.4233\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3547 - val_loss: 0.4253\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.3553\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=2, n_neurons=87, total=  41.6s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 2.3872 - val_loss: 1.2594\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.2068 - val_loss: 0.8868\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.8942 - val_loss: 0.7987\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8105 - val_loss: 0.7608\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7686 - val_loss: 0.7320\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.7406 - val_loss: 0.7125\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7187 - val_loss: 0.6966\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7000 - val_loss: 0.6810\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6825 - val_loss: 0.6637\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6676 - val_loss: 0.6534\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6530 - val_loss: 0.6399\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6398 - val_loss: 0.6295\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6268 - val_loss: 0.6184\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6144 - val_loss: 0.6079\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6030 - val_loss: 0.5996\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5915 - val_loss: 0.5931\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5809 - val_loss: 0.5817\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5706 - val_loss: 0.5742\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5607 - val_loss: 0.5665\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5511 - val_loss: 0.5571\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5420 - val_loss: 0.5533\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5336 - val_loss: 0.5445\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5251 - val_loss: 0.5396\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5170 - val_loss: 0.5327\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5093 - val_loss: 0.5267\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5021 - val_loss: 0.5225\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4951 - val_loss: 0.5166\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4886 - val_loss: 0.5136\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4824 - val_loss: 0.5089\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4765 - val_loss: 0.5051\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4709 - val_loss: 0.5013\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4656 - val_loss: 0.4971\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4606 - val_loss: 0.4939\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4559 - val_loss: 0.4915\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4515 - val_loss: 0.4880\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4469 - val_loss: 0.4843\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4435 - val_loss: 0.4829\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4397 - val_loss: 0.4818\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4362 - val_loss: 0.4789\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4330 - val_loss: 0.4776\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4301 - val_loss: 0.4750\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4271 - val_loss: 0.4729\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4243 - val_loss: 0.4717\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4217 - val_loss: 0.4693\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4193 - val_loss: 0.4690\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4171 - val_loss: 0.4669\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4147 - val_loss: 0.4668\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4126 - val_loss: 0.4644\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4105 - val_loss: 0.4624\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4088 - val_loss: 0.4611\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4071 - val_loss: 0.4604\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4053 - val_loss: 0.4601\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4037 - val_loss: 0.4584\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4022 - val_loss: 0.4569\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4005 - val_loss: 0.4553\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3993 - val_loss: 0.4558\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3979 - val_loss: 0.4549\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3964 - val_loss: 0.4545\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3953 - val_loss: 0.4536\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3941 - val_loss: 0.4526\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3928 - val_loss: 0.4525\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3915 - val_loss: 0.4507\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3908 - val_loss: 0.4501\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3896 - val_loss: 0.4500\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3887 - val_loss: 0.4484\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3878 - val_loss: 0.4479\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3868 - val_loss: 0.4480\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3859 - val_loss: 0.4478\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3850 - val_loss: 0.4469\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3842 - val_loss: 0.4458\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3832 - val_loss: 0.4470\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3826 - val_loss: 0.4455\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3817 - val_loss: 0.4451\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3807 - val_loss: 0.4449\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3803 - val_loss: 0.4445\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3795 - val_loss: 0.4435\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3787 - val_loss: 0.4427\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3779 - val_loss: 0.4430\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3772 - val_loss: 0.4427\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3767 - val_loss: 0.4425\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3760 - val_loss: 0.4415\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3754 - val_loss: 0.4410\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3747 - val_loss: 0.4408\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3741 - val_loss: 0.4408\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3735 - val_loss: 0.4400\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3730 - val_loss: 0.4404\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3722 - val_loss: 0.4398\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3717 - val_loss: 0.4392\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3714 - val_loss: 0.4393\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3709 - val_loss: 0.4390\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3703 - val_loss: 0.4391\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.3699 - val_loss: 0.4386\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3694 - val_loss: 0.4383\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3690 - val_loss: 0.4383\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3683 - val_loss: 0.4378\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3680 - val_loss: 0.4375\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3676 - val_loss: 0.4376\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3670 - val_loss: 0.4373\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3664 - val_loss: 0.4372\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3663 - val_loss: 0.4368\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3857\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  41.5s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 3.7649 - val_loss: 2.5328\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.0518 - val_loss: 1.9679\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.6095 - val_loss: 1.6497\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.3573 - val_loss: 1.3800\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 1.1658 - val_loss: 1.1695\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 1.0236 - val_loss: 1.0160\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.9247 - val_loss: 0.9126\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.8582 - val_loss: 0.8411\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8127 - val_loss: 0.7923\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7805 - val_loss: 0.7632\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7553 - val_loss: 0.7345\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7345 - val_loss: 0.7137\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.7165 - val_loss: 0.6990\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7000 - val_loss: 0.6831\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6849 - val_loss: 0.6696\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6712 - val_loss: 0.6626\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6581 - val_loss: 0.6503\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6455 - val_loss: 0.6454\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6340 - val_loss: 0.6345\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6223 - val_loss: 0.6247\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6115 - val_loss: 0.6187\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6009 - val_loss: 0.6106\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5909 - val_loss: 0.6043\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5814 - val_loss: 0.5989\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5723 - val_loss: 0.5910\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5635 - val_loss: 0.5872\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5552 - val_loss: 0.5796\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5474 - val_loss: 0.5761\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5401 - val_loss: 0.5690\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5329 - val_loss: 0.5646\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5259 - val_loss: 0.5611\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5194 - val_loss: 0.5555\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5131 - val_loss: 0.5514\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5072 - val_loss: 0.5480\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5017 - val_loss: 0.5419\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4960 - val_loss: 0.5366\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4911 - val_loss: 0.5339\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4860 - val_loss: 0.5318\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4813 - val_loss: 0.5280\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4767 - val_loss: 0.5243\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4724 - val_loss: 0.5211\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4683 - val_loss: 0.5181\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4643 - val_loss: 0.5144\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4603 - val_loss: 0.5123\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4567 - val_loss: 0.5089\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4530 - val_loss: 0.5062\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4495 - val_loss: 0.5042\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4458 - val_loss: 0.5007\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4424 - val_loss: 0.4976\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4392 - val_loss: 0.4953\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4362 - val_loss: 0.4932\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4333 - val_loss: 0.4928\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4303 - val_loss: 0.4885\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4279 - val_loss: 0.4867\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4253 - val_loss: 0.4862\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4229 - val_loss: 0.4832\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4206 - val_loss: 0.4807\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4184 - val_loss: 0.4810\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4165 - val_loss: 0.4788\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4145 - val_loss: 0.4768\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4124 - val_loss: 0.4776\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4104 - val_loss: 0.4730\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4091 - val_loss: 0.4727\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4072 - val_loss: 0.4705\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4056 - val_loss: 0.4702\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4041 - val_loss: 0.4691\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4025 - val_loss: 0.4675\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4010 - val_loss: 0.4677\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3997 - val_loss: 0.4656\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3982 - val_loss: 0.4642\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3968 - val_loss: 0.4648\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3956 - val_loss: 0.4629\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3943 - val_loss: 0.4616\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3931 - val_loss: 0.4600\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3921 - val_loss: 0.4600\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3910 - val_loss: 0.4584\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3899 - val_loss: 0.4590\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3889 - val_loss: 0.4582\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3878 - val_loss: 0.4566\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3870 - val_loss: 0.4563\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3859 - val_loss: 0.4565\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3851 - val_loss: 0.4546\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3841 - val_loss: 0.4545\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3833 - val_loss: 0.4533\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3825 - val_loss: 0.4526\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3817 - val_loss: 0.4525\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3807 - val_loss: 0.4534\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3800 - val_loss: 0.4512\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3794 - val_loss: 0.4511\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3785 - val_loss: 0.4511\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3779 - val_loss: 0.4501\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3772 - val_loss: 0.4500\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3765 - val_loss: 0.4491\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3758 - val_loss: 0.4486\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3752 - val_loss: 0.4481\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3744 - val_loss: 0.4485\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3739 - val_loss: 0.4474\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3731 - val_loss: 0.4476\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3726 - val_loss: 0.4464\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3721 - val_loss: 0.4466\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3900\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  39.8s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 2.9070 - val_loss: 1.5489\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.2882 - val_loss: 1.0384\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.9742 - val_loss: 0.8859\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.8517 - val_loss: 0.8071\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7864 - val_loss: 0.7567\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7436 - val_loss: 0.7220\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7132 - val_loss: 0.6975\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6891 - val_loss: 0.6793\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6690 - val_loss: 0.6608\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6512 - val_loss: 0.6477\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6353 - val_loss: 0.6331\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6208 - val_loss: 0.6215\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6073 - val_loss: 0.6128\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5951 - val_loss: 0.6027\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5836 - val_loss: 0.5935\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5731 - val_loss: 0.5852\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5633 - val_loss: 0.5777\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5540 - val_loss: 0.5725\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5454 - val_loss: 0.5641\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5374 - val_loss: 0.5588\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5299 - val_loss: 0.5540\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5229 - val_loss: 0.5492\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5162 - val_loss: 0.5429\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5101 - val_loss: 0.5405\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5044 - val_loss: 0.5349\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4990 - val_loss: 0.5321\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4940 - val_loss: 0.5286\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4892 - val_loss: 0.5244\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4848 - val_loss: 0.5210\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4805 - val_loss: 0.5176\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4766 - val_loss: 0.5160\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4729 - val_loss: 0.5117\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4694 - val_loss: 0.5091\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4660 - val_loss: 0.5085\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4630 - val_loss: 0.5048\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4600 - val_loss: 0.5020\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4573 - val_loss: 0.5005\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4547 - val_loss: 0.4995\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4521 - val_loss: 0.4997\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4500 - val_loss: 0.4957\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4478 - val_loss: 0.4939\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4456 - val_loss: 0.4929\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4435 - val_loss: 0.4904\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4416 - val_loss: 0.4890\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4398 - val_loss: 0.4869\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4381 - val_loss: 0.4862\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4364 - val_loss: 0.4841\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4349 - val_loss: 0.4835\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4334 - val_loss: 0.4817\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4319 - val_loss: 0.4804\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4304 - val_loss: 0.4781\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4292 - val_loss: 0.4789\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4277 - val_loss: 0.4767\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4266 - val_loss: 0.4762\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4252 - val_loss: 0.4749\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4241 - val_loss: 0.4745\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4228 - val_loss: 0.4720\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4216 - val_loss: 0.4729\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4207 - val_loss: 0.4713\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4187 - val_loss: 0.4690\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4176 - val_loss: 0.4679\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4166 - val_loss: 0.4689\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4156 - val_loss: 0.4651\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4149 - val_loss: 0.4661\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4140 - val_loss: 0.4642\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4132 - val_loss: 0.4636\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4124 - val_loss: 0.4632\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4115 - val_loss: 0.4632\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4107 - val_loss: 0.4607\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4098 - val_loss: 0.4611\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4092 - val_loss: 0.4600\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4083 - val_loss: 0.4595\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4076 - val_loss: 0.4585\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4069 - val_loss: 0.4577\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4062 - val_loss: 0.4569\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4054 - val_loss: 0.4566\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4047 - val_loss: 0.4553\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4039 - val_loss: 0.4541\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4033 - val_loss: 0.4542\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4025 - val_loss: 0.4539\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4018 - val_loss: 0.4529\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4011 - val_loss: 0.4525\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4004 - val_loss: 0.4507\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3998 - val_loss: 0.4507\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3990 - val_loss: 0.4497\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.3984 - val_loss: 0.4507\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3977 - val_loss: 0.4488\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3970 - val_loss: 0.4490\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3963 - val_loss: 0.4489\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3958 - val_loss: 0.4478\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3951 - val_loss: 0.4469\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3945 - val_loss: 0.4462\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3939 - val_loss: 0.4456\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3933 - val_loss: 0.4449\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3928 - val_loss: 0.4450\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3923 - val_loss: 0.4442\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3916 - val_loss: 0.4445\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3912 - val_loss: 0.4432\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3904 - val_loss: 0.4440\n",
      "3870/3870 [==============================] - 0s 48us/sample - loss: 0.3893\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=3, n_neurons=24, total=  39.2s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 2.1211 - val_loss: 0.8639\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9808 - val_loss: 1.7156\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 1.6776 - val_loss: 2.6247\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 3.8367 - val_loss: 5.3483\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 3.9032 - val_loss: 9.6709\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 11.5679 - val_loss: 23.9424\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 37.9562 - val_loss: 53.6974\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 37.4190 - val_loss: 138.4407\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 73.9304 - val_loss: 299.7757\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 213.6844 - val_loss: 692.3083\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 462.1570 - val_loss: 1558.2914\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 406.6080\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   4.7s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 1.4677 - val_loss: 0.6770\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5767 - val_loss: 0.6606\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5515 - val_loss: 0.6654\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5368 - val_loss: 0.6553\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5278 - val_loss: 0.6546\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5201 - val_loss: 0.6457\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5141 - val_loss: 0.6432\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5116 - val_loss: 0.6381\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5096 - val_loss: 0.6325\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5066 - val_loss: 0.6454\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5062 - val_loss: 0.6326\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.5038 - val_loss: 0.6352\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.5032 - val_loss: 0.6430\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5025 - val_loss: 0.6417\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5027 - val_loss: 0.6401\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5021 - val_loss: 0.6523\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.5014 - val_loss: 0.6509\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5021 - val_loss: 0.6506\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5007 - val_loss: 0.6381\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.9497\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   9.2s\n",
      "[CV] learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2 .....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 114us/sample - loss: 1.8572 - val_loss: 0.5753\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5987 - val_loss: 0.5437\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5559 - val_loss: 0.5423\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6727 - val_loss: 0.6361\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.6038 - val_loss: 0.6528\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.8763 - val_loss: 0.8447\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8241 - val_loss: 0.8791\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.4897 - val_loss: 1.0513\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 1.3526 - val_loss: 1.3381\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 2.5568 - val_loss: 1.6794\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.3688 - val_loss: 1.7321\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 2.9960 - val_loss: 2.6013\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.2731 - val_loss: 2.1689\n",
      "3870/3870 [==============================] - 0s 63us/sample - loss: 0.5291\n",
      "[CV]  learning_rate=0.006010328378268217, n_hidden=0, n_neurons=2, total=   7.2s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 1.2569 - val_loss: 0.9155\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.9780 - val_loss: 2.6160\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.7930 - val_loss: 0.5539\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4490 - val_loss: 0.4627\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4378 - val_loss: 0.6577\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5361 - val_loss: 0.6559\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.6511 - val_loss: 0.4348\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3706 - val_loss: 0.4258\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3659 - val_loss: 0.4295\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3618 - val_loss: 0.4234\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3581 - val_loss: 0.4260\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3550 - val_loss: 0.4378\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3531 - val_loss: 0.4384\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3503 - val_loss: 0.4218\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3494 - val_loss: 0.4169\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3485 - val_loss: 0.4163\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3462 - val_loss: 0.4191\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3451 - val_loss: 0.4211\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3438 - val_loss: 0.4160\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3429 - val_loss: 0.4156\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3408 - val_loss: 0.4108\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3400 - val_loss: 0.4146\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3397 - val_loss: 0.4100\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3373 - val_loss: 0.4170\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3364 - val_loss: 0.4069\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3354 - val_loss: 0.4219\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3343 - val_loss: 0.4077\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3324 - val_loss: 0.4107\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3298 - val_loss: 0.4056\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3285 - val_loss: 0.4051\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3260 - val_loss: 0.4051\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3247 - val_loss: 0.4071\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3230 - val_loss: 0.4054\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3215 - val_loss: 0.3989\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3205 - val_loss: 0.4025\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3201 - val_loss: 0.4068\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3205 - val_loss: 0.3975\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3172 - val_loss: 0.3968\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3170 - val_loss: 0.4029\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3175 - val_loss: 0.4306\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3164 - val_loss: 0.3976\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3151 - val_loss: 0.3991\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3135 - val_loss: 0.4072\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3129 - val_loss: 0.4074\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.3119 - val_loss: 0.4009\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3133 - val_loss: 0.4016\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3107 - val_loss: 0.3922\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3087 - val_loss: 0.3984\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3110 - val_loss: 0.4056\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3087 - val_loss: 0.4009\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3081 - val_loss: 0.3959\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3086 - val_loss: 0.3960\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3082 - val_loss: 0.3942\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3075 - val_loss: 0.3938\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3056 - val_loss: 0.4037\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3060 - val_loss: 0.3978\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3057 - val_loss: 0.3955\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3302\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=  24.1s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.8947 - val_loss: 0.6217\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5222 - val_loss: 0.5126\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4628 - val_loss: 0.4865\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4362 - val_loss: 0.4679\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4215 - val_loss: 0.4718\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 104us/sample - loss: 0.4122 - val_loss: 0.4532\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.4047 - val_loss: 0.4435\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4000 - val_loss: 0.4456\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3957 - val_loss: 0.4361\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3918 - val_loss: 0.4435\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3882 - val_loss: 0.4339\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3836 - val_loss: 0.4583\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3830 - val_loss: 0.4414\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3792 - val_loss: 0.4319\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3764 - val_loss: 0.4253\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3759 - val_loss: 0.4276\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3731 - val_loss: 0.4301\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3722 - val_loss: 0.4334\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3698 - val_loss: 0.4240\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3676 - val_loss: 0.4190\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3672 - val_loss: 0.4199\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3647 - val_loss: 0.4199\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3633 - val_loss: 0.4189\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3622 - val_loss: 0.4222\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3606 - val_loss: 0.4294\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3596 - val_loss: 0.4304\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3577 - val_loss: 0.4147\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3567 - val_loss: 0.4130\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3568 - val_loss: 0.4112\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3551 - val_loss: 0.4200\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3542 - val_loss: 0.4158\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3520 - val_loss: 0.4162\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3510 - val_loss: 0.4117\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3509 - val_loss: 0.4162\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3507 - val_loss: 0.4228\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3482 - val_loss: 0.4192\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3482 - val_loss: 0.4172\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3470 - val_loss: 0.4104\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3467 - val_loss: 0.4113\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3457 - val_loss: 0.4158\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3453 - val_loss: 0.4235\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3458 - val_loss: 0.4137\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3437 - val_loss: 0.4087\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3423 - val_loss: 0.4105\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3431 - val_loss: 0.4041\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3409 - val_loss: 0.4061\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3418 - val_loss: 0.4068\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3407 - val_loss: 0.4136\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3408 - val_loss: 0.4073\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3393 - val_loss: 0.4122\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3394 - val_loss: 0.4081\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3390 - val_loss: 0.4072\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3375 - val_loss: 0.4034\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.3370 - val_loss: 0.4023\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3369 - val_loss: 0.4101\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3362 - val_loss: 0.4040\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3366 - val_loss: 0.4035\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3356 - val_loss: 0.4041\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3344 - val_loss: 0.4035\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3338 - val_loss: 0.4023\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3334 - val_loss: 0.4119\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.3333 - val_loss: 0.4080\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3335 - val_loss: 0.4117\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3323 - val_loss: 0.4087\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3329 - val_loss: 0.4100\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3322 - val_loss: 0.4087\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3308 - val_loss: 0.4031\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3301 - val_loss: 0.4188\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3308 - val_loss: 0.4062\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.3296 - val_loss: 0.4051\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.3516\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=  30.2s\n",
      "[CV] learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 1.1191 - val_loss: 0.6513\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5587 - val_loss: 0.9810\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 1.1573 - val_loss: 0.6361\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6116 - val_loss: 0.6224\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5644 - val_loss: 0.4501\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4145 - val_loss: 0.4499\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4124 - val_loss: 0.4511\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4161 - val_loss: 0.4370\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3921 - val_loss: 0.4291\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3875 - val_loss: 0.4324\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3847 - val_loss: 0.4241\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3832 - val_loss: 0.4262\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3766 - val_loss: 0.4228\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3746 - val_loss: 0.4200\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3772 - val_loss: 0.4500\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3721 - val_loss: 0.4174\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3678 - val_loss: 0.4235\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3773 - val_loss: 0.4279\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3655 - val_loss: 0.4171\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3712 - val_loss: 0.4156\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3626 - val_loss: 0.4150\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3615 - val_loss: 0.4154\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3610 - val_loss: 0.4154\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3582 - val_loss: 0.4207\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3570 - val_loss: 0.4242\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3559 - val_loss: 0.4220\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3563 - val_loss: 0.4296\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.3863 - val_loss: 0.4162\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3762 - val_loss: 0.4239\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3641 - val_loss: 0.4161\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3547 - val_loss: 0.4090\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3587 - val_loss: 0.4120\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3508 - val_loss: 0.4114\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3500 - val_loss: 0.4119\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3485 - val_loss: 0.4167\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3503 - val_loss: 0.4080\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3468 - val_loss: 0.4130\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.3515 - val_loss: 0.4095\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3478 - val_loss: 0.4059\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3450 - val_loss: 0.4105\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3465 - val_loss: 0.4140\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3423 - val_loss: 0.4102\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3542 - val_loss: 0.4211\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3543 - val_loss: 0.4085\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3433 - val_loss: 0.3981\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3438 - val_loss: 0.4160\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3457 - val_loss: 0.4030\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3399 - val_loss: 0.4011\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3391 - val_loss: 0.4150\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4423 - val_loss: 0.4107\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3397 - val_loss: 0.4057\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3391 - val_loss: 0.4067\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3378 - val_loss: 0.4012\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3397 - val_loss: 0.4038\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3389 - val_loss: 0.4031\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.3374\n",
      "[CV]  learning_rate=0.008339092654580042, n_hidden=1, n_neurons=38, total=  22.8s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 4.0249 - val_loss: 2.7781\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 2.3117 - val_loss: 1.7780\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 1.6343 - val_loss: 1.4039\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 1.3424 - val_loss: 1.2253\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 1.1817 - val_loss: 1.1048\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.0700 - val_loss: 1.0173\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9890 - val_loss: 0.9494\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.9245 - val_loss: 0.8901\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.8705 - val_loss: 0.8403\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.8264 - val_loss: 0.8008\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.7890 - val_loss: 0.7668\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.7581 - val_loss: 0.7391\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.7322 - val_loss: 0.7166\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.7103 - val_loss: 0.6971\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6923 - val_loss: 0.6820\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6765 - val_loss: 0.6703\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6633 - val_loss: 0.6579\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6518 - val_loss: 0.6487\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6418 - val_loss: 0.6403\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6327 - val_loss: 0.6320\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6245 - val_loss: 0.6263\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6168 - val_loss: 0.6193\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6096 - val_loss: 0.6140\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6028 - val_loss: 0.6085\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5963 - val_loss: 0.6026\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5902 - val_loss: 0.5984\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5840 - val_loss: 0.5928\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5785 - val_loss: 0.5895\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5729 - val_loss: 0.5855\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5675 - val_loss: 0.5811\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5622 - val_loss: 0.5766\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5570 - val_loss: 0.5720\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5520 - val_loss: 0.5687\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5470 - val_loss: 0.5655\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5422 - val_loss: 0.5610\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5373 - val_loss: 0.5565\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5332 - val_loss: 0.5543\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5285 - val_loss: 0.5519\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5242 - val_loss: 0.5486\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5199 - val_loss: 0.5459\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5158 - val_loss: 0.5420\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5117 - val_loss: 0.5390\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5076 - val_loss: 0.5366\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5038 - val_loss: 0.5330\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5000 - val_loss: 0.5313\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4964 - val_loss: 0.5285\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4927 - val_loss: 0.5268\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4890 - val_loss: 0.5227\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4855 - val_loss: 0.5197\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4823 - val_loss: 0.5179\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4788 - val_loss: 0.5158\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4755 - val_loss: 0.5141\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4723 - val_loss: 0.5113\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4692 - val_loss: 0.5091\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4660 - val_loss: 0.5063\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4631 - val_loss: 0.5050\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4601 - val_loss: 0.5031\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4571 - val_loss: 0.5027\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4544 - val_loss: 0.5001\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4517 - val_loss: 0.4978\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4489 - val_loss: 0.4967\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4462 - val_loss: 0.4934\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4440 - val_loss: 0.4928\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.4415 - val_loss: 0.4916\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4390 - val_loss: 0.4889\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 0.4369 - val_loss: 0.4885\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 102us/sample - loss: 0.4346 - val_loss: 0.4869\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 107us/sample - loss: 0.4324 - val_loss: 0.4868\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4302 - val_loss: 0.4850\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4282 - val_loss: 0.4830\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4260 - val_loss: 0.4836\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.4243 - val_loss: 0.4808\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4224 - val_loss: 0.4801\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4204 - val_loss: 0.4796\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.4188 - val_loss: 0.4783\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4170 - val_loss: 0.4762\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4152 - val_loss: 0.4750\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4135 - val_loss: 0.4750\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4119 - val_loss: 0.4745\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4105 - val_loss: 0.4728\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4090 - val_loss: 0.4713\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4075 - val_loss: 0.4704\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4060 - val_loss: 0.4699\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4046 - val_loss: 0.4686\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4033 - val_loss: 0.4672\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4020 - val_loss: 0.4672\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4005 - val_loss: 0.4671\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3993 - val_loss: 0.4646\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3982 - val_loss: 0.4645\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3970 - val_loss: 0.4638\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3958 - val_loss: 0.4636\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3947 - val_loss: 0.4630\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3936 - val_loss: 0.4622\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3926 - val_loss: 0.4615\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3914 - val_loss: 0.4601\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.3906 - val_loss: 0.4607\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3896 - val_loss: 0.4611\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3887 - val_loss: 0.4600\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3877 - val_loss: 0.4592\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3870 - val_loss: 0.4583\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.3991\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  44.1s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 134us/sample - loss: 5.0596 - val_loss: 2.9480\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 2.1383 - val_loss: 1.4285\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.2774 - val_loss: 1.1571\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 1.0897 - val_loss: 1.0624\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.0049 - val_loss: 0.9835\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.9441 - val_loss: 0.9190\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.8975 - val_loss: 0.8644\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.8607 - val_loss: 0.8210\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8306 - val_loss: 0.7843\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.8060 - val_loss: 0.7575\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.7845 - val_loss: 0.7340\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7657 - val_loss: 0.7143\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7491 - val_loss: 0.7006\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7339 - val_loss: 0.6869\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7199 - val_loss: 0.6751\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7073 - val_loss: 0.6672\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6950 - val_loss: 0.6578\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6835 - val_loss: 0.6526\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6729 - val_loss: 0.6456\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.6624 - val_loss: 0.6396\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6528 - val_loss: 0.6360\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6435 - val_loss: 0.6323\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.6348 - val_loss: 0.6295\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.6266 - val_loss: 0.6276\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.6188 - val_loss: 0.6248\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6112 - val_loss: 0.6240\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6041 - val_loss: 0.6220\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5974 - val_loss: 0.6217\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5911 - val_loss: 0.6197\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5849 - val_loss: 0.6188\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5788 - val_loss: 0.6184\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5731 - val_loss: 0.6172\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5674 - val_loss: 0.6164\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5620 - val_loss: 0.6152\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5567 - val_loss: 0.6133\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5513 - val_loss: 0.6116\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5465 - val_loss: 0.6100\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5413 - val_loss: 0.6085\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5366 - val_loss: 0.6061\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5318 - val_loss: 0.6035\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5272 - val_loss: 0.6008\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5227 - val_loss: 0.5983\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5182 - val_loss: 0.5951\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5139 - val_loss: 0.5917\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5097 - val_loss: 0.5880\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5055 - val_loss: 0.5851\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5016 - val_loss: 0.5822\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4976 - val_loss: 0.5772\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4938 - val_loss: 0.5735\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4903 - val_loss: 0.5699\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4868 - val_loss: 0.5662\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4835 - val_loss: 0.5638\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4799 - val_loss: 0.5584\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4771 - val_loss: 0.5552\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4739 - val_loss: 0.5512\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4709 - val_loss: 0.5471\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4680 - val_loss: 0.5436\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4652 - val_loss: 0.5410\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4625 - val_loss: 0.5369\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4599 - val_loss: 0.5328\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4571 - val_loss: 0.5308\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4544 - val_loss: 0.5258\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4525 - val_loss: 0.5236\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4500 - val_loss: 0.5191\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4479 - val_loss: 0.5175\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4458 - val_loss: 0.5144\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4437 - val_loss: 0.5113\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4418 - val_loss: 0.5089\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4400 - val_loss: 0.5053\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4382 - val_loss: 0.5024\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4363 - val_loss: 0.5020\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4348 - val_loss: 0.4984\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4333 - val_loss: 0.4952\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4316 - val_loss: 0.4921\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4302 - val_loss: 0.4908\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 0.4288 - val_loss: 0.4879\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4274 - val_loss: 0.4869\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4261 - val_loss: 0.4848\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4247 - val_loss: 0.4830\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4236 - val_loss: 0.4803\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4223 - val_loss: 0.4792\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4212 - val_loss: 0.4773\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4201 - val_loss: 0.4762\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4190 - val_loss: 0.4737\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4180 - val_loss: 0.4723\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4170 - val_loss: 0.4717\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4157 - val_loss: 0.4722\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4150 - val_loss: 0.4676\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4142 - val_loss: 0.4667\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4132 - val_loss: 0.4672\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4124 - val_loss: 0.4652\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4116 - val_loss: 0.4645\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4108 - val_loss: 0.4626\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4100 - val_loss: 0.4613\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4093 - val_loss: 0.4606\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4085 - val_loss: 0.4610\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4078 - val_loss: 0.4608\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4070 - val_loss: 0.4611\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4064 - val_loss: 0.4582\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4057 - val_loss: 0.4580\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.4299\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  42.3s\n",
      "[CV] learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21 ..\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 4.4070 - val_loss: 3.2090\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 2.5644 - val_loss: 1.6966\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.4006 - val_loss: 1.0302\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.9858 - val_loss: 0.8476\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8391 - val_loss: 0.7754\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7683 - val_loss: 0.7349\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7267 - val_loss: 0.7081\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6991 - val_loss: 0.6907\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6798 - val_loss: 0.6768\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6650 - val_loss: 0.6667\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6528 - val_loss: 0.6568\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6422 - val_loss: 0.6493\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6325 - val_loss: 0.6430\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6236 - val_loss: 0.6365\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6152 - val_loss: 0.6291\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6072 - val_loss: 0.6228\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5993 - val_loss: 0.6169\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5916 - val_loss: 0.6123\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5842 - val_loss: 0.6057\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5769 - val_loss: 0.6002\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 108us/sample - loss: 0.5698 - val_loss: 0.5943\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5628 - val_loss: 0.5890\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5559 - val_loss: 0.5830\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5492 - val_loss: 0.5783\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5426 - val_loss: 0.5724\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5361 - val_loss: 0.5675\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5298 - val_loss: 0.5620\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5236 - val_loss: 0.5563\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5175 - val_loss: 0.5514\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5116 - val_loss: 0.5459\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.5059 - val_loss: 0.5420\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5005 - val_loss: 0.5372\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4953 - val_loss: 0.5325\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4902 - val_loss: 0.5289\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4856 - val_loss: 0.5239\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4811 - val_loss: 0.5197\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4768 - val_loss: 0.5163\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4728 - val_loss: 0.5131\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4689 - val_loss: 0.5100\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4653 - val_loss: 0.5063\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4618 - val_loss: 0.5033\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4586 - val_loss: 0.5005\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4554 - val_loss: 0.4978\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4525 - val_loss: 0.4949\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4496 - val_loss: 0.4921\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4470 - val_loss: 0.4902\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4445 - val_loss: 0.4875\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4421 - val_loss: 0.4856\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4398 - val_loss: 0.4833\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4376 - val_loss: 0.4816\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4354 - val_loss: 0.4795\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4335 - val_loss: 0.4781\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4315 - val_loss: 0.4762\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4297 - val_loss: 0.4747\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4280 - val_loss: 0.4734\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4263 - val_loss: 0.4722\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4246 - val_loss: 0.4704\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4231 - val_loss: 0.4694\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4217 - val_loss: 0.4681\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4203 - val_loss: 0.4672\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4190 - val_loss: 0.4662\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4176 - val_loss: 0.4650\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4164 - val_loss: 0.4643\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4151 - val_loss: 0.4630\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4141 - val_loss: 0.4622\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4129 - val_loss: 0.4612\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4119 - val_loss: 0.4604\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4108 - val_loss: 0.4597\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4097 - val_loss: 0.4591\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4087 - val_loss: 0.4582\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4078 - val_loss: 0.4575\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4069 - val_loss: 0.4567\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4060 - val_loss: 0.4561\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4051 - val_loss: 0.4552\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4043 - val_loss: 0.4545\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4034 - val_loss: 0.4541\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4026 - val_loss: 0.4536\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4019 - val_loss: 0.4529\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4011 - val_loss: 0.4521\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4004 - val_loss: 0.4520\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3996 - val_loss: 0.4512\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3989 - val_loss: 0.4507\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3982 - val_loss: 0.4502\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3975 - val_loss: 0.4495\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3970 - val_loss: 0.4492\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3963 - val_loss: 0.4487\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3957 - val_loss: 0.4483\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3951 - val_loss: 0.4478\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3945 - val_loss: 0.4472\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.3939 - val_loss: 0.4467\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3933 - val_loss: 0.4463\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3927 - val_loss: 0.4457\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3921 - val_loss: 0.4455\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3916 - val_loss: 0.4449\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3911 - val_loss: 0.4443\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3906 - val_loss: 0.4438\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3901 - val_loss: 0.4435\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3895 - val_loss: 0.4433\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3891 - val_loss: 0.4427\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.3885 - val_loss: 0.4430\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.3839\n",
      "[CV]  learning_rate=0.00030107783636342726, n_hidden=3, n_neurons=21, total=  39.9s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.4845 - val_loss: 1.0123\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8461 - val_loss: 0.6041\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5170 - val_loss: 0.5333\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4755 - val_loss: 0.5029\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4501 - val_loss: 0.5001\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4353 - val_loss: 0.4721\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4246 - val_loss: 0.4681\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.4170 - val_loss: 0.4631\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4120 - val_loss: 0.4603\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4074 - val_loss: 0.4598\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4038 - val_loss: 0.4537\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4013 - val_loss: 0.4539\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3988 - val_loss: 0.4567\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3962 - val_loss: 0.4529\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3945 - val_loss: 0.4436\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3931 - val_loss: 0.4434\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3912 - val_loss: 0.4457\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3890 - val_loss: 0.4449\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3889 - val_loss: 0.4442\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3872 - val_loss: 0.4409\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3850 - val_loss: 0.4398\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3849 - val_loss: 0.4433\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3836 - val_loss: 0.4380\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3821 - val_loss: 0.4421\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3807 - val_loss: 0.4411\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3805 - val_loss: 0.4471\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3801 - val_loss: 0.4370\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3786 - val_loss: 0.4413\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3770 - val_loss: 0.4336\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3766 - val_loss: 0.4392\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3758 - val_loss: 0.4372\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3749 - val_loss: 0.4399\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3740 - val_loss: 0.4334\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3735 - val_loss: 0.4340\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3723 - val_loss: 0.4328\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.3714 - val_loss: 0.4403\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3709 - val_loss: 0.4312\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3696 - val_loss: 0.4360\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3692 - val_loss: 0.4330\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3686 - val_loss: 0.4388\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3683 - val_loss: 0.4305\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3682 - val_loss: 0.4336\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3665 - val_loss: 0.4383\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3660 - val_loss: 0.4308\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3651 - val_loss: 0.4307\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3647 - val_loss: 0.4275\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3639 - val_loss: 0.4302\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3621 - val_loss: 0.4307\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3621 - val_loss: 0.4362\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3618 - val_loss: 0.4314\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3611 - val_loss: 0.4284\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3602 - val_loss: 0.4287\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3596 - val_loss: 0.4295\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3593 - val_loss: 0.4257\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3577 - val_loss: 0.4309\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3577 - val_loss: 0.4324\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3567 - val_loss: 0.4290\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3559 - val_loss: 0.4279\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3552 - val_loss: 0.4274\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3549 - val_loss: 0.4277\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3551 - val_loss: 0.4282\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3535 - val_loss: 0.4347\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3533 - val_loss: 0.4265\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3526 - val_loss: 0.4249\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3518 - val_loss: 0.4310\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3512 - val_loss: 0.4279\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3504 - val_loss: 0.4264\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3500 - val_loss: 0.4280\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3494 - val_loss: 0.4293\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3489 - val_loss: 0.4250\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3483 - val_loss: 0.4269\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.3478 - val_loss: 0.4302\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.3473 - val_loss: 0.4287\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 122us/sample - loss: 0.3467 - val_loss: 0.4224\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3464 - val_loss: 0.4254\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3463 - val_loss: 0.4260\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3453 - val_loss: 0.4234\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3439 - val_loss: 0.4240\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3447 - val_loss: 0.4227\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3434 - val_loss: 0.4243\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3429 - val_loss: 0.4278\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3426 - val_loss: 0.4213\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3428 - val_loss: 0.4238\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3427 - val_loss: 0.4276\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3412 - val_loss: 0.4222\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3406 - val_loss: 0.4222\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3402 - val_loss: 0.4221\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3401 - val_loss: 0.4275\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3402 - val_loss: 0.4255\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3395 - val_loss: 0.4235\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3392 - val_loss: 0.4230\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3389 - val_loss: 0.4239\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.3598\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  36.7s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 1.2414 - val_loss: 0.6405\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5775 - val_loss: 0.5606\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5142 - val_loss: 0.5290\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4808 - val_loss: 0.5136\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4607 - val_loss: 0.4998\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4453 - val_loss: 0.4821\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4315 - val_loss: 0.4704\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4235 - val_loss: 0.4597\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4159 - val_loss: 0.4504\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4089 - val_loss: 0.4526\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4051 - val_loss: 0.4439\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3998 - val_loss: 0.4489\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3988 - val_loss: 0.4434\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3943 - val_loss: 0.4396\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3902 - val_loss: 0.4416\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3896 - val_loss: 0.4389\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3867 - val_loss: 0.4371\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3837 - val_loss: 0.4390\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3818 - val_loss: 0.4374\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3793 - val_loss: 0.4310\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3787 - val_loss: 0.4341\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3764 - val_loss: 0.4330\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3748 - val_loss: 0.4307\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3730 - val_loss: 0.4328\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3724 - val_loss: 0.4324\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3711 - val_loss: 0.4349\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3699 - val_loss: 0.4258\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3685 - val_loss: 0.4269\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3688 - val_loss: 0.4244\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3675 - val_loss: 0.4280\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3661 - val_loss: 0.4277\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3647 - val_loss: 0.4239\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3638 - val_loss: 0.4251\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3635 - val_loss: 0.4255\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3629 - val_loss: 0.4228\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3609 - val_loss: 0.4212\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3609 - val_loss: 0.4217\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3599 - val_loss: 0.4187\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3595 - val_loss: 0.4197\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3595 - val_loss: 0.4200\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3577 - val_loss: 0.4282\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3586 - val_loss: 0.4199\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3570 - val_loss: 0.4176\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3553 - val_loss: 0.4192\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3559 - val_loss: 0.4150\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3547 - val_loss: 0.4163\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3548 - val_loss: 0.4157\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3540 - val_loss: 0.4179\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3538 - val_loss: 0.4173\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3527 - val_loss: 0.4164\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3526 - val_loss: 0.4177\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3526 - val_loss: 0.4187\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3508 - val_loss: 0.4140\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3513 - val_loss: 0.4123\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3511 - val_loss: 0.4161\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3507 - val_loss: 0.4129\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3497 - val_loss: 0.4136\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3497 - val_loss: 0.4142\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3486 - val_loss: 0.4128\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3482 - val_loss: 0.4117\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3479 - val_loss: 0.4174\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3473 - val_loss: 0.4152\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3475 - val_loss: 0.4153\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3465 - val_loss: 0.4120\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3465 - val_loss: 0.4131\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3464 - val_loss: 0.4115\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3457 - val_loss: 0.4096\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3445 - val_loss: 0.4176\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3449 - val_loss: 0.4119\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3441 - val_loss: 0.4106\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3430 - val_loss: 0.4128\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3425 - val_loss: 0.4147\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3428 - val_loss: 0.4095\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3425 - val_loss: 0.4071\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3425 - val_loss: 0.4100\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3416 - val_loss: 0.4074\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3412 - val_loss: 0.4102\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3403 - val_loss: 0.4133\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3406 - val_loss: 0.4059\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3397 - val_loss: 0.4078\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.3406 - val_loss: 0.4090\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3391 - val_loss: 0.4070\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3391 - val_loss: 0.4100\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.3394 - val_loss: 0.4067\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3398 - val_loss: 0.4052\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3382 - val_loss: 0.4105\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3382 - val_loss: 0.4147\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3377 - val_loss: 0.4116\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3369 - val_loss: 0.4065\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3372 - val_loss: 0.4059\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3369 - val_loss: 0.4079\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3357 - val_loss: 0.4102\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3356 - val_loss: 0.4076\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3354 - val_loss: 0.4079\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3354 - val_loss: 0.4085\n",
      "3870/3870 [==============================] - 0s 47us/sample - loss: 0.3465\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  36.6s\n",
      "[CV] learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 149us/sample - loss: 1.6836 - val_loss: 1.1026\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.9003 - val_loss: 0.5887\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5341 - val_loss: 0.5470\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.4987 - val_loss: 0.5174\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4742 - val_loss: 0.4979\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4585 - val_loss: 0.4863\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4479 - val_loss: 0.4803\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4401 - val_loss: 0.4732\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4336 - val_loss: 0.4670\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4284 - val_loss: 0.4666\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4241 - val_loss: 0.4610\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4208 - val_loss: 0.4623\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4175 - val_loss: 0.4580\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4147 - val_loss: 0.4570\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4124 - val_loss: 0.4580\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4098 - val_loss: 0.4533\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4073 - val_loss: 0.4539\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4050 - val_loss: 0.4538\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4031 - val_loss: 0.4507\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4014 - val_loss: 0.4499\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3995 - val_loss: 0.4511\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3979 - val_loss: 0.4496\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3958 - val_loss: 0.4485\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3941 - val_loss: 0.4503\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.392 - 0s 46us/sample - loss: 0.3928 - val_loss: 0.4504\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3914 - val_loss: 0.4500\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3899 - val_loss: 0.4459\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3890 - val_loss: 0.4477\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3879 - val_loss: 0.4448\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3867 - val_loss: 0.4466\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3855 - val_loss: 0.4471\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3841 - val_loss: 0.4446\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3827 - val_loss: 0.4426\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3824 - val_loss: 0.4453\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3813 - val_loss: 0.4488\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3805 - val_loss: 0.4419\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3797 - val_loss: 0.4443\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3789 - val_loss: 0.4435\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3777 - val_loss: 0.4440\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3773 - val_loss: 0.4454\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3776 - val_loss: 0.4439\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3750 - val_loss: 0.4469\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3757 - val_loss: 0.4423\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3733 - val_loss: 0.4449\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3727 - val_loss: 0.4379\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3726 - val_loss: 0.4468\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3722 - val_loss: 0.4406\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3714 - val_loss: 0.4388\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3706 - val_loss: 0.4461\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3724 - val_loss: 0.4414\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3689 - val_loss: 0.4392\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3694 - val_loss: 0.4441\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3682 - val_loss: 0.4381\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3678 - val_loss: 0.4427\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3672 - val_loss: 0.4398\n",
      "3870/3870 [==============================] - 0s 26us/sample - loss: 0.3685\n",
      "[CV]  learning_rate=0.005153286333701512, n_hidden=1, n_neurons=22, total=  22.1s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 7.7217 - val_loss: 6.0247\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 5.5388 - val_loss: 4.3790\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 4.0672 - val_loss: 3.2609\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 3.0653 - val_loss: 2.4907\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 2.3732 - val_loss: 1.9564\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.8924 - val_loss: 1.5810\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 1.5535 - val_loss: 1.3154\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 1.3132 - val_loss: 1.1271\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.1424 - val_loss: 0.9924\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.0195 - val_loss: 0.8947\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9299 - val_loss: 0.8237\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.8642 - val_loss: 0.7714\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8156 - val_loss: 0.7331\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7794 - val_loss: 0.7045\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.7520 - val_loss: 0.6829\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7311 - val_loss: 0.6665\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7149 - val_loss: 0.6540\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7023 - val_loss: 0.6441\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6923 - val_loss: 0.6363\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6841 - val_loss: 0.6300\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6773 - val_loss: 0.6248\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6715 - val_loss: 0.6203\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6664 - val_loss: 0.6163\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6621 - val_loss: 0.6129\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6580 - val_loss: 0.6097\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6545 - val_loss: 0.6068\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6511 - val_loss: 0.6041\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6480 - val_loss: 0.6016\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6451 - val_loss: 0.5991\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6422 - val_loss: 0.5968\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6396 - val_loss: 0.5946\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6370 - val_loss: 0.5924\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6345 - val_loss: 0.5903\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6321 - val_loss: 0.5882\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6296 - val_loss: 0.5862\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.6274 - val_loss: 0.5842\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6252 - val_loss: 0.5822\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6230 - val_loss: 0.5803\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6209 - val_loss: 0.5784\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.6189 - val_loss: 0.5766\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6169 - val_loss: 0.5749\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6149 - val_loss: 0.5731\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6129 - val_loss: 0.5714\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6111 - val_loss: 0.5698\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6091 - val_loss: 0.5681\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6074 - val_loss: 0.5665\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6057 - val_loss: 0.5649\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6040 - val_loss: 0.5634\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6023 - val_loss: 0.5618\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.6007 - val_loss: 0.5605\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.5989 - val_loss: 0.5590\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5974 - val_loss: 0.5576\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5959 - val_loss: 0.5563\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5944 - val_loss: 0.5550\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5929 - val_loss: 0.5537\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5914 - val_loss: 0.5525\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5900 - val_loss: 0.5512\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5886 - val_loss: 0.5501\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5873 - val_loss: 0.5489\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5860 - val_loss: 0.5478\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5847 - val_loss: 0.5466\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5834 - val_loss: 0.5456\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5822 - val_loss: 0.5445\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5809 - val_loss: 0.5434\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5797 - val_loss: 0.5424\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5786 - val_loss: 0.5414\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.5775 - val_loss: 0.5405\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5763 - val_loss: 0.5396\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5751 - val_loss: 0.5387\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5742 - val_loss: 0.5377\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5731 - val_loss: 0.5368\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5721 - val_loss: 0.5360\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5710 - val_loss: 0.5352\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5701 - val_loss: 0.5344\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5691 - val_loss: 0.5335\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5682 - val_loss: 0.5328\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5673 - val_loss: 0.5320\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5664 - val_loss: 0.5313\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5655 - val_loss: 0.5306\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5646 - val_loss: 0.5298\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5638 - val_loss: 0.5291\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5629 - val_loss: 0.5285\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5621 - val_loss: 0.5278\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5614 - val_loss: 0.5272\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5606 - val_loss: 0.5265\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5598 - val_loss: 0.5260\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5591 - val_loss: 0.5253\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5584 - val_loss: 0.5248\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5577 - val_loss: 0.5243\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5570 - val_loss: 0.5238\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5563 - val_loss: 0.5232\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5556 - val_loss: 0.5227\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5550 - val_loss: 0.5222\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5544 - val_loss: 0.5217\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5537 - val_loss: 0.5213\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5530 - val_loss: 0.5207\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5525 - val_loss: 0.5202\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5520 - val_loss: 0.5198\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5513 - val_loss: 0.5194\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5507 - val_loss: 0.5190\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.5582\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=  36.2s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 7.6319 - val_loss: 6.7168\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 5.6945 - val_loss: 5.0827\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 4.3241 - val_loss: 3.9219\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 3.3431 - val_loss: 3.0891\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 2.6344 - val_loss: 2.4857\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 2.1176 - val_loss: 2.0451\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.7381 - val_loss: 1.7213\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.4574 - val_loss: 1.4814\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 1.2484 - val_loss: 1.3031\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.0921 - val_loss: 1.1697\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9744 - val_loss: 1.0693\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8855 - val_loss: 0.9935\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.8178 - val_loss: 0.9358\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7659 - val_loss: 0.8917\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7260 - val_loss: 0.8578\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6950 - val_loss: 0.8316\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6709 - val_loss: 0.8111\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.6518 - val_loss: 0.7950\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6366 - val_loss: 0.7822\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6245 - val_loss: 0.7721\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6147 - val_loss: 0.7639\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6067 - val_loss: 0.7571\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6000 - val_loss: 0.7516\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5944 - val_loss: 0.7469\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5896 - val_loss: 0.7430\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5855 - val_loss: 0.7396\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5818 - val_loss: 0.7368\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5787 - val_loss: 0.7341\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5758 - val_loss: 0.7319\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5732 - val_loss: 0.7299\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5709 - val_loss: 0.7281\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5687 - val_loss: 0.7264\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5666 - val_loss: 0.7247\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5647 - val_loss: 0.7233\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5629 - val_loss: 0.7219\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5612 - val_loss: 0.7206\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5596 - val_loss: 0.7194\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.5581 - val_loss: 0.7182\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5566 - val_loss: 0.7171\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.5551 - val_loss: 0.7161\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.5537 - val_loss: 0.7150\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.5524 - val_loss: 0.7141\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.5511 - val_loss: 0.7132\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5498 - val_loss: 0.7122\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5486 - val_loss: 0.7113\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5474 - val_loss: 0.7104\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5463 - val_loss: 0.7095\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5452 - val_loss: 0.7087\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5441 - val_loss: 0.7079\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5430 - val_loss: 0.7071\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5420 - val_loss: 0.7064\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5410 - val_loss: 0.7057\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5400 - val_loss: 0.7049\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.5390 - val_loss: 0.7041\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.5381 - val_loss: 0.7033\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5371 - val_loss: 0.7027\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5362 - val_loss: 0.7019\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.5354 - val_loss: 0.7013\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5345 - val_loss: 0.7006\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5337 - val_loss: 0.6999\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5329 - val_loss: 0.6994\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5321 - val_loss: 0.6987\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5313 - val_loss: 0.6981\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5305 - val_loss: 0.6975\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5298 - val_loss: 0.6969\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5291 - val_loss: 0.6964\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5284 - val_loss: 0.6958\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5277 - val_loss: 0.6952\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.5270 - val_loss: 0.6947\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5263 - val_loss: 0.6941\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5257 - val_loss: 0.6935\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5250 - val_loss: 0.6930\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5244 - val_loss: 0.6924\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.5238 - val_loss: 0.6918\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5232 - val_loss: 0.6913\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 111us/sample - loss: 0.5227 - val_loss: 0.6908\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5221 - val_loss: 0.6903\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5215 - val_loss: 0.6898\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5210 - val_loss: 0.6893\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5205 - val_loss: 0.6889\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5200 - val_loss: 0.6884\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5195 - val_loss: 0.6879\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5190 - val_loss: 0.6874\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5185 - val_loss: 0.6870\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5181 - val_loss: 0.6865\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5176 - val_loss: 0.6860\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5171 - val_loss: 0.6856\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5167 - val_loss: 0.6851\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5162 - val_loss: 0.6847\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5158 - val_loss: 0.6843\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5154 - val_loss: 0.6839\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5150 - val_loss: 0.6834\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5146 - val_loss: 0.6830\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5142 - val_loss: 0.6826\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5139 - val_loss: 0.6823\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5135 - val_loss: 0.6818\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5131 - val_loss: 0.6815\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5128 - val_loss: 0.6811\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5125 - val_loss: 0.6808\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5121 - val_loss: 0.6805\n",
      "3870/3870 [==============================] - 0s 28us/sample - loss: 1.0513\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=  45.8s\n",
      "[CV] learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 6.1534 - val_loss: 4.8027\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 4.4875 - val_loss: 3.5601\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 3.3698 - val_loss: 2.7103\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 2.6022 - val_loss: 2.1197\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 2.0664 - val_loss: 1.7034\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.6865 - val_loss: 1.4070\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.4144 - val_loss: 1.1942\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.2173 - val_loss: 1.0400\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 1.0732 - val_loss: 0.9279\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.9674 - val_loss: 0.8460\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8892 - val_loss: 0.7860\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8310 - val_loss: 0.7418\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7874 - val_loss: 0.7090\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7544 - val_loss: 0.6844\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7294 - val_loss: 0.6660\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.7101 - val_loss: 0.6520\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6951 - val_loss: 0.6412\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6833 - val_loss: 0.6327\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6738 - val_loss: 0.6259\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6660 - val_loss: 0.6203\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6597 - val_loss: 0.6156\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6543 - val_loss: 0.6116\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6496 - val_loss: 0.6082\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6456 - val_loss: 0.6050\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6419 - val_loss: 0.6021\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6386 - val_loss: 0.5994\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6356 - val_loss: 0.5969\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6326 - val_loss: 0.5944\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6300 - val_loss: 0.5921\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6275 - val_loss: 0.5898\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6251 - val_loss: 0.5876\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6226 - val_loss: 0.5854\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6204 - val_loss: 0.5833\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6183 - val_loss: 0.5813\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6162 - val_loss: 0.5793\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6141 - val_loss: 0.5773\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6122 - val_loss: 0.5753\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6103 - val_loss: 0.5734\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6084 - val_loss: 0.5716\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6066 - val_loss: 0.5698\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6047 - val_loss: 0.5680\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6029 - val_loss: 0.5662\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6013 - val_loss: 0.5645\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5996 - val_loss: 0.5628\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5980 - val_loss: 0.5612\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5964 - val_loss: 0.5596\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5948 - val_loss: 0.5580\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5933 - val_loss: 0.5564\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5918 - val_loss: 0.5549\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5904 - val_loss: 0.5534\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5890 - val_loss: 0.5520\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5876 - val_loss: 0.5505\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5862 - val_loss: 0.5492\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5849 - val_loss: 0.5478\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5837 - val_loss: 0.5466\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5822 - val_loss: 0.5453\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5810 - val_loss: 0.5440\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5798 - val_loss: 0.5428\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5786 - val_loss: 0.5416\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5775 - val_loss: 0.5404\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5764 - val_loss: 0.5393\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5753 - val_loss: 0.5382\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5742 - val_loss: 0.5372\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5731 - val_loss: 0.5361\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5721 - val_loss: 0.5350\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5711 - val_loss: 0.5340\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5702 - val_loss: 0.5330\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5691 - val_loss: 0.5320\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5682 - val_loss: 0.5312\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5674 - val_loss: 0.5303\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5663 - val_loss: 0.5294\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5655 - val_loss: 0.5285\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5646 - val_loss: 0.5277\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5638 - val_loss: 0.5269\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5630 - val_loss: 0.5261\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5622 - val_loss: 0.5253\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5614 - val_loss: 0.5245\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5606 - val_loss: 0.5237\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5598 - val_loss: 0.5230\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5592 - val_loss: 0.5223\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5584 - val_loss: 0.5216\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5577 - val_loss: 0.5210\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5570 - val_loss: 0.5203\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5564 - val_loss: 0.5196\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5557 - val_loss: 0.5190\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5551 - val_loss: 0.5184\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5544 - val_loss: 0.5178\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5538 - val_loss: 0.5172\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5531 - val_loss: 0.5166\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5526 - val_loss: 0.5161\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5521 - val_loss: 0.5155\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5515 - val_loss: 0.5150\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5508 - val_loss: 0.5145\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5504 - val_loss: 0.5140\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5499 - val_loss: 0.5135\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5494 - val_loss: 0.5131\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5489 - val_loss: 0.5126\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5483 - val_loss: 0.5121\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5479 - val_loss: 0.5117\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5474 - val_loss: 0.5113\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5491\n",
      "[CV]  learning_rate=0.0003099230412972121, n_hidden=0, n_neurons=49, total=  33.6s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 1.3940 - val_loss: 0.7782\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7302 - val_loss: 0.6333\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5546 - val_loss: 0.5459\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4725 - val_loss: 0.5026\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4407 - val_loss: 0.5076\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4230 - val_loss: 0.4683\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4089 - val_loss: 0.4664\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4005 - val_loss: 0.4538\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3942 - val_loss: 0.4650\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3864 - val_loss: 0.4500\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3800 - val_loss: 0.4392\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3767 - val_loss: 0.4373\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3722 - val_loss: 0.4385\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3676 - val_loss: 0.4332\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3643 - val_loss: 0.4251\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3632 - val_loss: 0.4247\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3595 - val_loss: 0.4272\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3570 - val_loss: 0.4264\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3560 - val_loss: 0.4236\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3534 - val_loss: 0.4181\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3507 - val_loss: 0.4204\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3495 - val_loss: 0.4227\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3480 - val_loss: 0.4162\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3457 - val_loss: 0.4238\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3439 - val_loss: 0.4178\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3441 - val_loss: 0.4220\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3432 - val_loss: 0.4161\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3405 - val_loss: 0.4228\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3384 - val_loss: 0.4105\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3375 - val_loss: 0.4168\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3359 - val_loss: 0.4144\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3349 - val_loss: 0.4166\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3345 - val_loss: 0.4129\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3332 - val_loss: 0.4117\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3315 - val_loss: 0.4103\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3310 - val_loss: 0.4154\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3300 - val_loss: 0.4103\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3284 - val_loss: 0.4117\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3280 - val_loss: 0.4114\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3275 - val_loss: 0.4230\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3269 - val_loss: 0.4089\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3261 - val_loss: 0.4111\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3250 - val_loss: 0.4221\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3245 - val_loss: 0.4095\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3232 - val_loss: 0.4094\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3247 - val_loss: 0.4068\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3227 - val_loss: 0.4083\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3202 - val_loss: 0.4077\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3215 - val_loss: 0.4114\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3202 - val_loss: 0.4066\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3193 - val_loss: 0.4046\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.3185 - val_loss: 0.4046\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3177 - val_loss: 0.4049\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3176 - val_loss: 0.4029\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3159 - val_loss: 0.4090\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.3159 - val_loss: 0.4088\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3149 - val_loss: 0.4028\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3141 - val_loss: 0.4041\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3134 - val_loss: 0.4024\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3129 - val_loss: 0.4017\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3121 - val_loss: 0.4018\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3114 - val_loss: 0.4090\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3111 - val_loss: 0.4010\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3103 - val_loss: 0.4008\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3096 - val_loss: 0.4034\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3092 - val_loss: 0.4010\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3087 - val_loss: 0.3986\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3081 - val_loss: 0.4017\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3073 - val_loss: 0.4023\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3066 - val_loss: 0.3980\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3057 - val_loss: 0.3998\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3053 - val_loss: 0.4025\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3051 - val_loss: 0.4030\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3045 - val_loss: 0.3989\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3040 - val_loss: 0.3998\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.3037 - val_loss: 0.3964\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3028 - val_loss: 0.3947\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.3013 - val_loss: 0.3943\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3017 - val_loss: 0.3960\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3005 - val_loss: 0.3964\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3002 - val_loss: 0.4026\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.2996 - val_loss: 0.3941\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.2998 - val_loss: 0.3965\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.2996 - val_loss: 0.3979\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.2977 - val_loss: 0.3935\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2972 - val_loss: 0.3916\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.2968 - val_loss: 0.3940\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.2969 - val_loss: 0.4042\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.2966 - val_loss: 0.3987\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 118us/sample - loss: 0.2957 - val_loss: 0.3967\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.2947 - val_loss: 0.3957\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 0.2945 - val_loss: 0.3950\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.2940 - val_loss: 0.4019\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.2944 - val_loss: 0.3953\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.2931 - val_loss: 0.4002\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2941 - val_loss: 0.3928\n",
      "3870/3870 [==============================] - 0s 37us/sample - loss: 0.3233\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  43.5s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 111us/sample - loss: 1.1931 - val_loss: 0.6703\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6049 - val_loss: 0.5910\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5370 - val_loss: 0.5505\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4909 - val_loss: 0.5278\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.4622 - val_loss: 0.5120\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4407 - val_loss: 0.4870\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4252 - val_loss: 0.4710\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4137 - val_loss: 0.4614\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4047 - val_loss: 0.4503\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3967 - val_loss: 0.4531\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3903 - val_loss: 0.4424\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3837 - val_loss: 0.4464\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3797 - val_loss: 0.4414\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3754 - val_loss: 0.4367\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3709 - val_loss: 0.4336\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3683 - val_loss: 0.4351\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3648 - val_loss: 0.4326\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3628 - val_loss: 0.4344\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3601 - val_loss: 0.4309\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3581 - val_loss: 0.4258\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3565 - val_loss: 0.4276\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3540 - val_loss: 0.4242\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3520 - val_loss: 0.4229\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3501 - val_loss: 0.4233\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3489 - val_loss: 0.4231\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3470 - val_loss: 0.4264\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3455 - val_loss: 0.4181\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3441 - val_loss: 0.4163\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3434 - val_loss: 0.4152\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3415 - val_loss: 0.4179\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3401 - val_loss: 0.4159\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3390 - val_loss: 0.4137\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3371 - val_loss: 0.4133\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3372 - val_loss: 0.4141\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3364 - val_loss: 0.4139\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3343 - val_loss: 0.4142\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3337 - val_loss: 0.4111\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3326 - val_loss: 0.4077\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3317 - val_loss: 0.4072\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3308 - val_loss: 0.4097\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3296 - val_loss: 0.4115\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3294 - val_loss: 0.4060\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3273 - val_loss: 0.4048\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3265 - val_loss: 0.4058\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3267 - val_loss: 0.3993\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3250 - val_loss: 0.4005\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3249 - val_loss: 0.4006\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3237 - val_loss: 0.4009\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3231 - val_loss: 0.4023\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.3217 - val_loss: 0.4033\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3220 - val_loss: 0.4026\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.3208 - val_loss: 0.4024\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3197 - val_loss: 0.3999\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3189 - val_loss: 0.3981\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3184 - val_loss: 0.4022\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3177 - val_loss: 0.3978\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3177 - val_loss: 0.3974\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3166 - val_loss: 0.3978\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3157 - val_loss: 0.3956\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3153 - val_loss: 0.3938\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3142 - val_loss: 0.3974\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3136 - val_loss: 0.3998\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3134 - val_loss: 0.3981\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3120 - val_loss: 0.3921\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3119 - val_loss: 0.3991\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3115 - val_loss: 0.3984\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3107 - val_loss: 0.3946\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3097 - val_loss: 0.3986\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3099 - val_loss: 0.3944\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3088 - val_loss: 0.3925\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3073 - val_loss: 0.3924\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3071 - val_loss: 0.3935\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3066 - val_loss: 0.3931\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3064 - val_loss: 0.3921\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3062 - val_loss: 0.3897\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3047 - val_loss: 0.3926\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3038 - val_loss: 0.3903\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3033 - val_loss: 0.3949\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3027 - val_loss: 0.3909\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3026 - val_loss: 0.3902\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3024 - val_loss: 0.3956\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3013 - val_loss: 0.3875\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3012 - val_loss: 0.3883\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3008 - val_loss: 0.3902\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3007 - val_loss: 0.3880\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2996 - val_loss: 0.3891\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2990 - val_loss: 0.3927\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2987 - val_loss: 0.3971\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2976 - val_loss: 0.3933\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2975 - val_loss: 0.3867\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.2973 - val_loss: 0.3896\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2967 - val_loss: 0.3930\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.2960 - val_loss: 0.3912\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2952 - val_loss: 0.3935\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2954 - val_loss: 0.3905\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2941 - val_loss: 0.3866\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.2942 - val_loss: 0.3913\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.2933 - val_loss: 0.3853\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.2932 - val_loss: 0.3901\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.2934 - val_loss: 0.3883\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3151\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  40.9s\n",
      "[CV] learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 1.1176 - val_loss: 0.7572\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7068 - val_loss: 0.6459\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5988 - val_loss: 0.5732\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5253 - val_loss: 0.5428\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4824 - val_loss: 0.4997\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4547 - val_loss: 0.4864\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4355 - val_loss: 0.4708\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4245 - val_loss: 0.4615\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4133 - val_loss: 0.4510\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4061 - val_loss: 0.4512\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3993 - val_loss: 0.4422\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3928 - val_loss: 0.4432\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3898 - val_loss: 0.4371\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3842 - val_loss: 0.4355\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3808 - val_loss: 0.4368\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3764 - val_loss: 0.4275\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.3740 - val_loss: 0.4299\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3700 - val_loss: 0.4264\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3663 - val_loss: 0.4237\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3701 - val_loss: 0.4228\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3631 - val_loss: 0.4196\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3601 - val_loss: 0.4194\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3576 - val_loss: 0.4167\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3553 - val_loss: 0.4228\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3531 - val_loss: 0.4218\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3537 - val_loss: 0.4217\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3499 - val_loss: 0.4172\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3520 - val_loss: 0.4152\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3483 - val_loss: 0.4097\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3481 - val_loss: 0.4144\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3458 - val_loss: 0.4164\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3438 - val_loss: 0.4138\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3440 - val_loss: 0.4109\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3413 - val_loss: 0.4126\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3429 - val_loss: 0.4147\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3395 - val_loss: 0.4084\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3388 - val_loss: 0.4131\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3424 - val_loss: 0.4089\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3362 - val_loss: 0.4128\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.3417 - val_loss: 0.4323\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3532 - val_loss: 0.4210\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3477 - val_loss: 0.4128\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3387 - val_loss: 0.4127\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3354 - val_loss: 0.4134\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3324 - val_loss: 0.4034\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3331 - val_loss: 0.4141\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3331 - val_loss: 0.4084\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3319 - val_loss: 0.4036\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.3295 - val_loss: 0.4137\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3376 - val_loss: 0.4128\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3310 - val_loss: 0.4126\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3296 - val_loss: 0.4070\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3284 - val_loss: 0.4046\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3287 - val_loss: 0.4055\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3288 - val_loss: 0.4076\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.3309\n",
      "[CV]  learning_rate=0.0033625641252688094, n_hidden=2, n_neurons=42, total=  22.4s\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610/11610 [==============================] - 1s 66us/sample - loss: 1.0377 - val_loss: 0.7151\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.5969 - val_loss: 0.5555\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 90us/sample - loss: 0.4811 - val_loss: 0.5011\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 105us/sample - loss: 0.4390 - val_loss: 0.4748\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 0.4160 - val_loss: 0.4615\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.4016 - val_loss: 0.4506\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3904 - val_loss: 0.4463\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3833 - val_loss: 0.4361\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3763 - val_loss: 0.4344\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3712 - val_loss: 0.4337\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3667 - val_loss: 0.4274\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3634 - val_loss: 0.4337\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3597 - val_loss: 0.4259\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3566 - val_loss: 0.4311\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3545 - val_loss: 0.4258\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3522 - val_loss: 0.4187\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3503 - val_loss: 0.4219\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3474 - val_loss: 0.4179\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3460 - val_loss: 0.4214\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3443 - val_loss: 0.4180\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3419 - val_loss: 0.4174\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3401 - val_loss: 0.4193\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3392 - val_loss: 0.4109\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3373 - val_loss: 0.4134\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3350 - val_loss: 0.4115\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3340 - val_loss: 0.4130\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3324 - val_loss: 0.4114\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.3317 - val_loss: 0.4108\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3296 - val_loss: 0.4171\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3289 - val_loss: 0.4098\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3274 - val_loss: 0.4094\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3268 - val_loss: 0.4063\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3251 - val_loss: 0.4081\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3258 - val_loss: 0.4045\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3233 - val_loss: 0.4052\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3226 - val_loss: 0.4018\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3219 - val_loss: 0.4063\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3204 - val_loss: 0.4058\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.3189 - val_loss: 0.4041\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3193 - val_loss: 0.4020\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3182 - val_loss: 0.4064\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3192 - val_loss: 0.4170\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3163 - val_loss: 0.4050\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3163 - val_loss: 0.4056\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3148 - val_loss: 0.4038\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3138 - val_loss: 0.4030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd2aa146400>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fd2a8125a58>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,...\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the model into the randomized_search\n",
    "rand_search_cv = RandomizedSearchCV(keras_regressor, parameters_distributions, n_iter=10, cv=3, verbose=2)\n",
    "\n",
    "#train the different possible models\n",
    "rand_search_cv.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_train_validation), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0033625641252688094, 'n_hidden': 2, 'n_neurons': 42}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32308116009479754"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 25us/sample - loss: 0.3719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3719119927333307"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare on unseen data\n",
    "rand_search_cv.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the best model from the search\n",
    "model = rand_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 28us/sample - loss: 0.3719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3719119927333307"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
